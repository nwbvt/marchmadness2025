{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b53588-2c8e-4166-b01d-037b765c2d69",
   "metadata": {},
   "source": [
    "# March Madness 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd96dd0b-1844-4dca-9495-b722deda29ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81669670-3bd9-4cc0-b0e8-d76f32dfd61f",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "Each team can be modeled by x hidden features. In each game, these hidden features interact in a nonlinear fashion to determine the outcome of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef008b05-6dc7-46e7-9783-2499977b8249",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5186f8-4158-462e-9d34-da6230804b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.00000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "      <td>117748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2014.146355</td>\n",
       "      <td>70.294986</td>\n",
       "      <td>1288.25451</td>\n",
       "      <td>75.878936</td>\n",
       "      <td>1283.138830</td>\n",
       "      <td>63.888287</td>\n",
       "      <td>0.068689</td>\n",
       "      <td>26.401824</td>\n",
       "      <td>55.760242</td>\n",
       "      <td>7.347445</td>\n",
       "      <td>...</td>\n",
       "      <td>20.159790</td>\n",
       "      <td>12.073403</td>\n",
       "      <td>17.732454</td>\n",
       "      <td>10.461740</td>\n",
       "      <td>21.625650</td>\n",
       "      <td>11.409722</td>\n",
       "      <td>13.888907</td>\n",
       "      <td>6.004739</td>\n",
       "      <td>2.868185</td>\n",
       "      <td>19.305780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.515929</td>\n",
       "      <td>35.772556</td>\n",
       "      <td>105.34750</td>\n",
       "      <td>10.998547</td>\n",
       "      <td>104.795432</td>\n",
       "      <td>10.848767</td>\n",
       "      <td>0.305098</td>\n",
       "      <td>4.680314</td>\n",
       "      <td>7.456374</td>\n",
       "      <td>3.119260</td>\n",
       "      <td>...</td>\n",
       "      <td>6.068136</td>\n",
       "      <td>5.344049</td>\n",
       "      <td>7.081056</td>\n",
       "      <td>4.221039</td>\n",
       "      <td>4.518197</td>\n",
       "      <td>3.724567</td>\n",
       "      <td>4.382700</td>\n",
       "      <td>2.745969</td>\n",
       "      <td>2.019050</td>\n",
       "      <td>4.553353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1101.00000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1199.00000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1287.00000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1282.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1381.00000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1480.00000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Season         DayNum       WTeamID         WScore  \\\n",
       "count  117748.000000  117748.000000  117748.00000  117748.000000   \n",
       "mean     2014.146355      70.294986    1288.25451      75.878936   \n",
       "std         6.515929      35.772556     105.34750      10.998547   \n",
       "min      2003.000000       0.000000    1101.00000      34.000000   \n",
       "25%      2009.000000      40.000000    1199.00000      68.000000   \n",
       "50%      2014.000000      73.000000    1287.00000      75.000000   \n",
       "75%      2020.000000     101.000000    1381.00000      83.000000   \n",
       "max      2025.000000     132.000000    1480.00000     149.000000   \n",
       "\n",
       "             LTeamID         LScore          NumOT           WFGM  \\\n",
       "count  117748.000000  117748.000000  117748.000000  117748.000000   \n",
       "mean     1283.138830      63.888287       0.068689      26.401824   \n",
       "std       104.795432      10.848767       0.305098       4.680314   \n",
       "min      1101.000000      20.000000       0.000000      10.000000   \n",
       "25%      1192.000000      57.000000       0.000000      23.000000   \n",
       "50%      1282.000000      64.000000       0.000000      26.000000   \n",
       "75%      1374.000000      71.000000       0.000000      29.000000   \n",
       "max      1480.000000     144.000000       6.000000      57.000000   \n",
       "\n",
       "                WFGA          WFGM3  ...          LFGA3           LFTM  \\\n",
       "count  117748.000000  117748.000000  ...  117748.000000  117748.000000   \n",
       "mean       55.760242       7.347445  ...      20.159790      12.073403   \n",
       "std         7.456374       3.119260  ...       6.068136       5.344049   \n",
       "min        26.000000       0.000000  ...       1.000000       0.000000   \n",
       "25%        51.000000       5.000000  ...      16.000000       8.000000   \n",
       "50%        55.000000       7.000000  ...      20.000000      12.000000   \n",
       "75%        60.000000       9.000000  ...      24.000000      15.000000   \n",
       "max       103.000000      26.000000  ...      59.000000      48.000000   \n",
       "\n",
       "                LFTA            LOR            LDR           LAst  \\\n",
       "count  117748.000000  117748.000000  117748.000000  117748.000000   \n",
       "mean       17.732454      10.461740      21.625650      11.409722   \n",
       "std         7.081056       4.221039       4.518197       3.724567   \n",
       "min         0.000000       0.000000       4.000000       0.000000   \n",
       "25%        13.000000       7.000000      19.000000       9.000000   \n",
       "50%        17.000000      10.000000      21.000000      11.000000   \n",
       "75%        22.000000      13.000000      25.000000      14.000000   \n",
       "max        65.000000      36.000000      49.000000      31.000000   \n",
       "\n",
       "                 LTO           LStl           LBlk            LPF  \n",
       "count  117748.000000  117748.000000  117748.000000  117748.000000  \n",
       "mean       13.888907       6.004739       2.868185      19.305780  \n",
       "std         4.382700       2.745969       2.019050       4.553353  \n",
       "min         0.000000       0.000000       0.000000       4.000000  \n",
       "25%        11.000000       4.000000       1.000000      16.000000  \n",
       "50%        14.000000       6.000000       3.000000      19.000000  \n",
       "75%        17.000000       8.000000       4.000000      22.000000  \n",
       "max        41.000000      22.000000      18.000000      45.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mens = pd.read_csv('data/MRegularSeasonDetailedResults.csv')\n",
    "mens['League'] = 'M'\n",
    "mens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3be43b-6f29-44ab-bd21-55159ffe58be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "      <td>80626.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017.404609</td>\n",
       "      <td>69.183626</td>\n",
       "      <td>3285.116823</td>\n",
       "      <td>71.706633</td>\n",
       "      <td>3286.689554</td>\n",
       "      <td>57.242044</td>\n",
       "      <td>0.051708</td>\n",
       "      <td>25.847034</td>\n",
       "      <td>58.966574</td>\n",
       "      <td>6.276077</td>\n",
       "      <td>...</td>\n",
       "      <td>17.918413</td>\n",
       "      <td>10.507392</td>\n",
       "      <td>15.503808</td>\n",
       "      <td>11.360020</td>\n",
       "      <td>22.422122</td>\n",
       "      <td>10.935852</td>\n",
       "      <td>17.150745</td>\n",
       "      <td>7.109977</td>\n",
       "      <td>2.820839</td>\n",
       "      <td>18.192990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.582659</td>\n",
       "      <td>36.157922</td>\n",
       "      <td>104.073477</td>\n",
       "      <td>11.536993</td>\n",
       "      <td>105.505327</td>\n",
       "      <td>10.960867</td>\n",
       "      <td>0.259072</td>\n",
       "      <td>4.978157</td>\n",
       "      <td>7.969144</td>\n",
       "      <td>3.127369</td>\n",
       "      <td>...</td>\n",
       "      <td>6.456006</td>\n",
       "      <td>4.936838</td>\n",
       "      <td>6.630184</td>\n",
       "      <td>4.640191</td>\n",
       "      <td>4.936106</td>\n",
       "      <td>3.805935</td>\n",
       "      <td>5.277180</td>\n",
       "      <td>3.192300</td>\n",
       "      <td>2.062848</td>\n",
       "      <td>4.556919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3101.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3101.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3196.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3195.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>3283.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>3287.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>3376.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3377.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Season        DayNum       WTeamID        WScore       LTeamID  \\\n",
       "count  80626.000000  80626.000000  80626.000000  80626.000000  80626.000000   \n",
       "mean    2017.404609     69.183626   3285.116823     71.706633   3286.689554   \n",
       "std        4.582659     36.157922    104.073477     11.536993    105.505327   \n",
       "min     2010.000000      0.000000   3101.000000     30.000000   3101.000000   \n",
       "25%     2013.000000     36.000000   3196.000000     64.000000   3195.000000   \n",
       "50%     2017.000000     73.000000   3283.000000     71.000000   3287.000000   \n",
       "75%     2022.000000    101.000000   3376.000000     79.000000   3377.000000   \n",
       "max     2025.000000    132.000000   3480.000000    140.000000   3480.000000   \n",
       "\n",
       "             LScore         NumOT          WFGM          WFGA         WFGM3  \\\n",
       "count  80626.000000  80626.000000  80626.000000  80626.000000  80626.000000   \n",
       "mean      57.242044      0.051708     25.847034     58.966574      6.276077   \n",
       "std       10.960867      0.259072      4.978157      7.969144      3.127369   \n",
       "min       11.000000      0.000000      9.000000     30.000000      0.000000   \n",
       "25%       50.000000      0.000000     22.000000     53.000000      4.000000   \n",
       "50%       57.000000      0.000000     25.000000     59.000000      6.000000   \n",
       "75%       64.000000      0.000000     29.000000     64.000000      8.000000   \n",
       "max      130.000000      5.000000     58.000000    113.000000     30.000000   \n",
       "\n",
       "       ...         LFGA3          LFTM          LFTA           LOR  \\\n",
       "count  ...  80626.000000  80626.000000  80626.000000  80626.000000   \n",
       "mean   ...     17.918413     10.507392     15.503808     11.360020   \n",
       "std    ...      6.456006      4.936838      6.630184      4.640191   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...     13.000000      7.000000     11.000000      8.000000   \n",
       "50%    ...     17.000000     10.000000     15.000000     11.000000   \n",
       "75%    ...     22.000000     14.000000     20.000000     14.000000   \n",
       "max    ...     80.000000     37.000000     52.000000     38.000000   \n",
       "\n",
       "                LDR          LAst           LTO          LStl          LBlk  \\\n",
       "count  80626.000000  80626.000000  80626.000000  80626.000000  80626.000000   \n",
       "mean      22.422122     10.935852     17.150745      7.109977      2.820839   \n",
       "std        4.936106      3.805935      5.277180      3.192300      2.062848   \n",
       "min        1.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%       19.000000      8.000000     13.000000      5.000000      1.000000   \n",
       "50%       22.000000     11.000000     17.000000      7.000000      2.000000   \n",
       "75%       26.000000     13.000000     20.000000      9.000000      4.000000   \n",
       "max       53.000000     34.000000     49.000000     26.000000     21.000000   \n",
       "\n",
       "                LPF  \n",
       "count  80626.000000  \n",
       "mean      18.192990  \n",
       "std        4.556919  \n",
       "min        3.000000  \n",
       "25%       15.000000  \n",
       "50%       18.000000  \n",
       "75%       21.000000  \n",
       "max       47.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womens = pd.read_csv('data/WRegularSeasonDetailedResults.csv')\n",
    "womens['League'] = 'W'\n",
    "womens.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a57ce-cca2-4b81-a8a2-ad8638faefbe",
   "metadata": {},
   "source": [
    "The IDs are definitely distinct so we can combine into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c18b78-f8fb-439f-bdeb-079abb4516f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([mens, womens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6210e5c-c7a9-4ec3-95f6-b4a963a6d191",
   "metadata": {},
   "source": [
    "Get the distinct team/Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2206f762-b26b-49a2-b97a-94929f7273e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat([data[['WTeamID', 'Season', 'League']].rename(columns={'WTeamID': 'TeamID'}),\n",
    "                   data[['LTeamID', 'Season', 'League']].rename(columns={'LTeamID': 'TeamID'})]).drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee119045-207e-4dae-9ec7-1ef186642f48",
   "metadata": {},
   "source": [
    "Define the training data. The x's will be the indexes of two team IDs, the y's will be 1 if the first team won, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607aaaf7-13f0-461e-8b2a-7477c1f57bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teamMapping = {(x.TeamID, x.Season): x.Index for x in teams.itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d52abd-7d74-4996-a93b-ab2e578bdf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>League</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80621</th>\n",
       "      <td>2025</td>\n",
       "      <td>106</td>\n",
       "      <td>3242</td>\n",
       "      <td>63</td>\n",
       "      <td>3416</td>\n",
       "      <td>58</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80622</th>\n",
       "      <td>2025</td>\n",
       "      <td>106</td>\n",
       "      <td>3329</td>\n",
       "      <td>68</td>\n",
       "      <td>3428</td>\n",
       "      <td>64</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80623</th>\n",
       "      <td>2025</td>\n",
       "      <td>106</td>\n",
       "      <td>3349</td>\n",
       "      <td>72</td>\n",
       "      <td>3194</td>\n",
       "      <td>39</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80624</th>\n",
       "      <td>2025</td>\n",
       "      <td>106</td>\n",
       "      <td>3378</td>\n",
       "      <td>70</td>\n",
       "      <td>3150</td>\n",
       "      <td>52</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80625</th>\n",
       "      <td>2025</td>\n",
       "      <td>106</td>\n",
       "      <td>3404</td>\n",
       "      <td>73</td>\n",
       "      <td>3398</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198374 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  \\\n",
       "0        2003      10     1104      68     1328      62    N      0    27   \n",
       "1        2003      10     1272      70     1393      63    N      0    26   \n",
       "2        2003      11     1266      73     1437      61    N      0    24   \n",
       "3        2003      11     1296      56     1457      50    N      0    18   \n",
       "4        2003      11     1400      77     1208      71    N      0    30   \n",
       "...       ...     ...      ...     ...      ...     ...  ...    ...   ...   \n",
       "80621    2025     106     3242      63     3416      58    H      0    17   \n",
       "80622    2025     106     3329      68     3428      64    A      0    23   \n",
       "80623    2025     106     3349      72     3194      39    H      0    30   \n",
       "80624    2025     106     3378      70     3150      52    A      0    25   \n",
       "80625    2025     106     3404      73     3398      52    H      0    24   \n",
       "\n",
       "       WFGA  ...  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  League  \n",
       "0        58  ...    16    22   10   22     8   18     9     2   20       M  \n",
       "1        62  ...     9    20   20   25     7   12     8     6   16       M  \n",
       "2        58  ...    14    23   31   22     9   12     2     5   23       M  \n",
       "3        38  ...     8    15   17   20     9   19     4     3   23       M  \n",
       "4        61  ...    17    27   21   15    12   10     7     1   14       M  \n",
       "...     ...  ...   ...   ...  ...  ...   ...  ...   ...   ...  ...     ...  \n",
       "80621    46  ...     5    11   15   21    11   12     4     2   21       W  \n",
       "80622    63  ...     9    16    8   18    16   11     8     6   20       W  \n",
       "80623    63  ...    16    23    4   25     5   10     4     3    9       W  \n",
       "80624    59  ...    11    14    7   24     5   15     8     2   15       W  \n",
       "80625    57  ...     9    15   12   22     8   20    12     2   20       W  \n",
       "\n",
       "[198374 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f2c1e7-5289-431c-a2e4-50fea2c15249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(data):\n",
    "    winners = data.apply(lambda x: teamMapping[(x.WTeamID, x.Season)], axis=1)\n",
    "    losers = data.apply(lambda x: teamMapping[(x.LTeamID, x.Season)], axis=1)\n",
    "    x_tensor = torch.from_numpy(np.concatenate([np.stack([winners, losers], axis=1), np.stack([losers, winners], axis=1)]))\n",
    "    y_tensor = torch.from_numpy(np.concatenate([(data.WScore-data.LScore), (data.LScore-data.WScore)]).reshape((-1,1))).double()\n",
    "    return TensorDataset(x_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57ad178-fdaf-4e87-a0b7-959876a5d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = gen_dataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e570534-09f4-4e6a-b9bd-e77e52014ce5",
   "metadata": {},
   "source": [
    "Generate the train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbc8b7f-0b20-4f49-92e9-f16cadfeeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "\n",
    "generator = torch.Generator().manual_seed(20250217)\n",
    "train_data, validation_data = torch.utils.data.random_split(dataset, [0.95, 0.05], generator=generator)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50ea84-42ce-462c-a3b3-3928a04aa7ef",
   "metadata": {},
   "source": [
    "## The Model\n",
    "Define the model. Combine the embeddings for the two teams, go to a hidden layer, and then output to a prediction if the first team won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5dbb96c-d80f-454e-bdda-f2d9eadd3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_size=64, model_size=16, dropout=0.1):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(teams), embedding_size)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(2*embedding_size, model_size)\n",
    "        self.score_fc = nn.Linear(model_size, 1)\n",
    "        self.result_fc = nn.Linear(model_size, 1)\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        team = self.embedding(x[:,0])\n",
    "        opponent = self.embedding(x[:,1])\n",
    "        matchup = self.dropout1(torch.cat([team, opponent], axis=1))\n",
    "        hidden = self.dropout2(F.relu(self.fc1(matchup)))\n",
    "        score = self.score_fc(hidden)\n",
    "        result = F.sigmoid(self.result_fc(hidden))\n",
    "        return score, result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5629261-0b6d-44c9-828e-698e86006f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(embedding_size=128, model_size=64, dropout=0.25).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98325a-8ba0-466f-b3ca-6991e8450a08",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cb92ad-908f-44a7-a2a0-88dd9d4d51ab",
   "metadata": {},
   "source": [
    "Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab2ee77-d1dd-444f-b7bc-b5e7d057ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "def train(data, model, loss_fn, optimizer, full_loss=True):\n",
    "    size = len(data.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(data):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred_score, pred_result = model(x)\n",
    "        actual_result = (y > 0).double()\n",
    "        score_loss = loss_fn(pred_score, y)\n",
    "        result_loss = loss_fn(pred_result, actual_result)\n",
    "        if full_loss:\n",
    "            (score_loss + 10 * result_loss).backward()\n",
    "        else:\n",
    "            result_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            score_loss, result_loss, current = score_loss.item(), result_loss.item(), (batch + 1) * len(x)\n",
    "            print(f\"score loss: {score_loss:>7f}, result loss: {result_loss:>7f} [{current:>6d}/{size:>6d}]\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadb0b3-4e99-47a2-8fee-846467b01b86",
   "metadata": {},
   "source": [
    "Define the testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3466d44f-fc82-46a7-95e1-0590674e7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, model, loss_fn, label=\"Test\"):\n",
    "    size = len(data.dataset)\n",
    "    num_batches = len(data)\n",
    "    model.eval()\n",
    "    score_loss, result_loss, correct = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            score_pred, result_pred = model(x)\n",
    "            actual_result = (y > 0).double()\n",
    "            score_loss += loss_fn(score_pred, y).item()\n",
    "            result_loss += loss_fn(result_pred, actual_result)\n",
    "            correct += ((result_pred >= 0.5) == (actual_result == 1)).type(torch.float).sum().item()\n",
    "    score_loss /= num_batches\n",
    "    result_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"{label}: Accuracy: {(100*correct):>0.1f}%, Score loss: {score_loss:>8f}, Result loss: {result_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fca87-08c7-48e0-92dd-52ef4ff8463f",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d07ac18-5a7c-4088-a83b-324aee0c54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train: Accuracy: 58.1%, Score loss: 259.632630, Result loss: 0.241159\n",
      "Validation: Accuracy: 57.5%, Score loss: 260.685737, Result loss: 0.242353\n",
      "Epoch 1\n",
      "Train: Accuracy: 64.9%, Score loss: 225.729596, Result loss: 0.219980\n",
      "Validation: Accuracy: 64.0%, Score loss: 230.557499, Result loss: 0.223598\n",
      "Epoch 2\n",
      "Train: Accuracy: 69.3%, Score loss: 195.021155, Result loss: 0.200477\n",
      "Validation: Accuracy: 68.1%, Score loss: 202.399891, Result loss: 0.206178\n",
      "Epoch 3\n",
      "Train: Accuracy: 72.1%, Score loss: 171.112397, Result loss: 0.185808\n",
      "Validation: Accuracy: 70.6%, Score loss: 180.220591, Result loss: 0.193139\n",
      "Epoch 4\n",
      "Train: Accuracy: 73.9%, Score loss: 154.755154, Result loss: 0.175642\n",
      "Validation: Accuracy: 72.0%, Score loss: 164.617941, Result loss: 0.183754\n",
      "Epoch 5\n",
      "Train: Accuracy: 75.0%, Score loss: 143.922457, Result loss: 0.169271\n",
      "Validation: Accuracy: 73.0%, Score loss: 154.132503, Result loss: 0.177815\n",
      "Epoch 6\n",
      "Train: Accuracy: 75.6%, Score loss: 136.800581, Result loss: 0.165415\n",
      "Validation: Accuracy: 73.8%, Score loss: 147.121347, Result loss: 0.174070\n",
      "Epoch 7\n",
      "Train: Accuracy: 75.9%, Score loss: 131.770879, Result loss: 0.163212\n",
      "Validation: Accuracy: 74.1%, Score loss: 142.082035, Result loss: 0.172010\n",
      "Epoch 8\n",
      "Train: Accuracy: 76.1%, Score loss: 128.505397, Result loss: 0.161471\n",
      "Validation: Accuracy: 74.4%, Score loss: 138.582637, Result loss: 0.170234\n",
      "Epoch 9\n",
      "Train: Accuracy: 76.3%, Score loss: 126.294150, Result loss: 0.160474\n",
      "Validation: Accuracy: 74.5%, Score loss: 136.256713, Result loss: 0.169203\n",
      "Epoch 10\n",
      "Train: Accuracy: 76.4%, Score loss: 124.672724, Result loss: 0.159900\n",
      "Validation: Accuracy: 74.6%, Score loss: 134.676486, Result loss: 0.168696\n",
      "Epoch 11\n",
      "Train: Accuracy: 76.5%, Score loss: 122.996598, Result loss: 0.159160\n",
      "Validation: Accuracy: 74.8%, Score loss: 132.703522, Result loss: 0.167795\n",
      "Epoch 12\n",
      "Train: Accuracy: 76.5%, Score loss: 121.956600, Result loss: 0.158880\n",
      "Validation: Accuracy: 74.8%, Score loss: 131.649351, Result loss: 0.167482\n",
      "Epoch 13\n",
      "Train: Accuracy: 76.5%, Score loss: 121.101166, Result loss: 0.158520\n",
      "Validation: Accuracy: 74.9%, Score loss: 130.706826, Result loss: 0.167109\n",
      "Epoch 14\n",
      "Train: Accuracy: 76.6%, Score loss: 120.596950, Result loss: 0.158449\n",
      "Validation: Accuracy: 74.9%, Score loss: 130.168353, Result loss: 0.166920\n",
      "Epoch 15\n",
      "Train: Accuracy: 76.6%, Score loss: 119.950402, Result loss: 0.158077\n",
      "Validation: Accuracy: 75.0%, Score loss: 129.426903, Result loss: 0.166601\n",
      "Epoch 16\n",
      "Train: Accuracy: 76.6%, Score loss: 119.327410, Result loss: 0.157806\n",
      "Validation: Accuracy: 75.0%, Score loss: 128.800535, Result loss: 0.166439\n",
      "Epoch 17\n",
      "Train: Accuracy: 76.6%, Score loss: 118.973830, Result loss: 0.157750\n",
      "Validation: Accuracy: 75.1%, Score loss: 128.438194, Result loss: 0.166332\n",
      "Epoch 18\n",
      "Train: Accuracy: 76.6%, Score loss: 118.735031, Result loss: 0.157675\n",
      "Validation: Accuracy: 75.0%, Score loss: 128.195182, Result loss: 0.166299\n",
      "Epoch 19\n",
      "Train: Accuracy: 76.6%, Score loss: 118.461375, Result loss: 0.157470\n",
      "Validation: Accuracy: 75.0%, Score loss: 127.931223, Result loss: 0.166146\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Epoch {i}\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(train_loader, model, loss_fn, label=\"Train\")\n",
    "    test(validation_loader, model, loss_fn, label=\"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aaf28c-130c-4579-a627-7475f7abc2a2",
   "metadata": {},
   "source": [
    "Fine tune with only the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4074860-e773-4900-96d3-7859687f15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train: Accuracy: 76.6%, Score loss: 118.416099, Result loss: 0.157343\n",
      "Validation: Accuracy: 75.0%, Score loss: 127.888337, Result loss: 0.166071\n",
      "Epoch 1\n",
      "Train: Accuracy: 76.6%, Score loss: 118.401010, Result loss: 0.157100\n",
      "Validation: Accuracy: 75.1%, Score loss: 127.880492, Result loss: 0.165969\n",
      "Epoch 2\n",
      "Train: Accuracy: 76.7%, Score loss: 118.373521, Result loss: 0.156441\n",
      "Validation: Accuracy: 75.0%, Score loss: 127.874743, Result loss: 0.165722\n",
      "Epoch 3\n",
      "Train: Accuracy: 77.1%, Score loss: 118.545003, Result loss: 0.154547\n",
      "Validation: Accuracy: 75.1%, Score loss: 128.064450, Result loss: 0.164978\n",
      "Epoch 4\n",
      "Train: Accuracy: 77.5%, Score loss: 118.988274, Result loss: 0.152649\n",
      "Validation: Accuracy: 75.2%, Score loss: 128.603569, Result loss: 0.164350\n",
      "Epoch 5\n",
      "Train: Accuracy: 77.8%, Score loss: 119.890495, Result loss: 0.151092\n",
      "Validation: Accuracy: 75.2%, Score loss: 129.660673, Result loss: 0.164154\n",
      "Epoch 6\n",
      "Train: Accuracy: 78.1%, Score loss: 121.145905, Result loss: 0.150126\n",
      "Validation: Accuracy: 75.2%, Score loss: 131.173291, Result loss: 0.164005\n",
      "Epoch 7\n",
      "Train: Accuracy: 78.2%, Score loss: 122.548949, Result loss: 0.149887\n",
      "Validation: Accuracy: 75.3%, Score loss: 132.769900, Result loss: 0.164217\n",
      "Epoch 8\n",
      "Train: Accuracy: 78.3%, Score loss: 124.089472, Result loss: 0.149200\n",
      "Validation: Accuracy: 75.3%, Score loss: 134.638709, Result loss: 0.164478\n",
      "Epoch 9\n",
      "Train: Accuracy: 78.3%, Score loss: 125.512928, Result loss: 0.148899\n",
      "Validation: Accuracy: 75.2%, Score loss: 136.223162, Result loss: 0.164622\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Epoch {i}\")\n",
    "    train(train_loader, model, loss_fn, optimizer, full_loss=False)\n",
    "    test(train_loader, model, loss_fn, label=\"Train\")\n",
    "    test(validation_loader, model, loss_fn, label=\"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55a843-9fa3-443f-8342-410abd74688c",
   "metadata": {},
   "source": [
    "With this model we can predict the output of about three quarters of regular season games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe60ad-2cd9-4339-9600-62264350e6bd",
   "metadata": {},
   "source": [
    "## Load the tourney data to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093fcd61-386e-4330-b5af-e9d93df1b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "mens_tourney = pd.read_csv('data/MNCAATourneyDetailedResults.csv')\n",
    "womens_tourney = pd.read_csv('data/WNCAATourneyDetailedResults.csv')\n",
    "tourney = pd.concat([mens_tourney, womens_tourney])\n",
    "\n",
    "tourney_dataset = gen_dataset(tourney)\n",
    "tourney_loader = DataLoader(tourney_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08340cd1-6cb0-400a-80fa-dda1171789bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tourney: Accuracy: 72.9%, Score loss: 143.922916, Result loss: 0.173403\n"
     ]
    }
   ],
   "source": [
    "test(tourney_loader, model, loss_fn, label=\"Tourney\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7c18a-8267-4926-a191-5c3a218bfde2",
   "metadata": {},
   "source": [
    "When it comes to tournament results we get about 7 out of 10 results. The lower result is likely due to teams having increased pairity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8ba4d-cd61-4693-9cda-963ecca19c07",
   "metadata": {},
   "source": [
    "### Performance by year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fda1ddd2-af9c-4bed-9812-fc24e0c56d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003 Tournament: Accuracy: 67.2%, Score loss: 148.399814, Result loss: 0.207213\n",
      "2004 Tournament: Accuracy: 71.9%, Score loss: 120.700810, Result loss: 0.210350\n",
      "2005 Tournament: Accuracy: 74.2%, Score loss: 93.888995, Result loss: 0.185747\n",
      "2006 Tournament: Accuracy: 68.0%, Score loss: 112.387519, Result loss: 0.227212\n",
      "2007 Tournament: Accuracy: 81.2%, Score loss: 92.082273, Result loss: 0.153581\n",
      "2008 Tournament: Accuracy: 73.4%, Score loss: 153.820765, Result loss: 0.167643\n",
      "2009 Tournament: Accuracy: 77.3%, Score loss: 131.938593, Result loss: 0.165084\n",
      "2010 Tournament: Accuracy: 71.7%, Score loss: 124.564780, Result loss: 0.172917\n",
      "2011 Tournament: Accuracy: 68.5%, Score loss: 145.110581, Result loss: 0.179811\n",
      "2012 Tournament: Accuracy: 77.7%, Score loss: 113.500898, Result loss: 0.147950\n",
      "2013 Tournament: Accuracy: 70.8%, Score loss: 167.666320, Result loss: 0.181573\n",
      "2014 Tournament: Accuracy: 70.0%, Score loss: 149.198077, Result loss: 0.164372\n",
      "2015 Tournament: Accuracy: 77.3%, Score loss: 110.177124, Result loss: 0.148492\n",
      "2016 Tournament: Accuracy: 72.3%, Score loss: 165.496078, Result loss: 0.183033\n",
      "2017 Tournament: Accuracy: 77.7%, Score loss: 178.798933, Result loss: 0.163063\n",
      "2018 Tournament: Accuracy: 75.8%, Score loss: 188.975222, Result loss: 0.173505\n",
      "2019 Tournament: Accuracy: 74.2%, Score loss: 129.097248, Result loss: 0.147218\n",
      "2021 Tournament: Accuracy: 67.1%, Score loss: 186.789687, Result loss: 0.196072\n",
      "2022 Tournament: Accuracy: 71.6%, Score loss: 171.843512, Result loss: 0.187872\n",
      "2023 Tournament: Accuracy: 67.5%, Score loss: 169.228147, Result loss: 0.197597\n",
      "2024 Tournament: Accuracy: 76.9%, Score loss: 132.671593, Result loss: 0.153965\n"
     ]
    }
   ],
   "source": [
    "for season in tourney.Season.unique():\n",
    "    loader = DataLoader(gen_dataset(tourney[tourney.Season == season]), batch_size=batch_size)\n",
    "    test(loader, model, loss_fn, label=f\"{season} Tournament\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda0d55-f6e3-4901-bd45-5ef699110c0f",
   "metadata": {},
   "source": [
    "## Final tuning\n",
    "Finally we can train with the early tournament data, pre 2021, as the latter will be used in the submission and we don't want to overfit. We should freeze the embedding layer as the actual evaluation will be on teams where we don't have tourney data to train for. We only want to train the inner layers that determine whether or not a particular vector will win"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924bf0db-3222-47d3-98dd-114b68c2687b",
   "metadata": {},
   "source": [
    "tourney_train_loader = DataLoader(gen_dataset(tourney[tourney.Season < 2021]), shuffle=True, batch_size=8)\n",
    "tourney_test_loader = DataLoader(gen_dataset(tourney[tourney.Season >= 2021]), batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb08fd-98ba-4e8b-a8ef-7c503d4a7bbc",
   "metadata": {},
   "source": [
    "for param in model.embedding.parameters():\n",
    "    param.requires_grad = False\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e71e2b-89a8-4243-865a-c5e439de28fb",
   "metadata": {},
   "source": [
    "for i in range(10):\n",
    "    print(f\"Epoch {i}\")\n",
    "    train(tourney_train_loader, model, loss_fn, optimizer, full_loss=False)\n",
    "    test(tourney_train_loader, model, loss_fn, label=\"Train\")\n",
    "    test(tourney_test_loader, model, loss_fn, label=\"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afd4bc-a7fc-43bd-a1b6-1b37a85f8f79",
   "metadata": {},
   "source": [
    "## Generating the submission file\n",
    "### Phase 1\n",
    "\n",
    "Write the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d25dfe-9ead-4100-bb12-fbab95124ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w') as f:\n",
    "    f.write(\"ID,Pred\\n\")\n",
    "    season=2025\n",
    "    for league in ('M', 'W'):\n",
    "        teams_to_test = sorted(teams[(teams.Season==season) & (teams.League==league)].TeamID.values)\n",
    "        matchups = [(t1, t2) for t1 in teams_to_test for t2 in teams_to_test if t1 < t2]\n",
    "        matchups_tensor = torch.Tensor([(teamMapping[(t1, season)], teamMapping[(t2, season)])\n",
    "                                 for (t1, t2) in matchups]).int().to(device)\n",
    "        _, predictions = model(matchups_tensor)\n",
    "        for (t1, t2), pred in zip(matchups, predictions):\n",
    "            f.write(f\"{season}_{t1.item()}_{t2.item()},{pred.item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e032b5e-322d-49a5-a9a7-9d34972a56dd",
   "metadata": {},
   "source": [
    "Two teams canceled their 2021 season due to covid but are still in the sample submission. Add in their results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3b7d8-88d5-4f18-aad2-ce4ede2941f9",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c29f148-ac3b-47fa-9ed5-dd4f7fa6852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb64c5-f3c5-4ea7-afba-944d25c4a903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
