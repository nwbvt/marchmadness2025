{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b53588-2c8e-4166-b01d-037b765c2d69",
   "metadata": {},
   "source": [
    "# March Madness 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd96dd0b-1844-4dca-9495-b722deda29ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81669670-3bd9-4cc0-b0e8-d76f32dfd61f",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "Each team can be modeled by x hidden features. In each game, these hidden features interact in a nonlinear fashion to determine the outcome of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef008b05-6dc7-46e7-9783-2499977b8249",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5186f8-4158-462e-9d34-da6230804b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2014.051044</td>\n",
       "      <td>70.072462</td>\n",
       "      <td>1288.243422</td>\n",
       "      <td>75.859651</td>\n",
       "      <td>1283.044987</td>\n",
       "      <td>63.857732</td>\n",
       "      <td>0.068658</td>\n",
       "      <td>26.392099</td>\n",
       "      <td>55.746305</td>\n",
       "      <td>7.339085</td>\n",
       "      <td>...</td>\n",
       "      <td>20.138276</td>\n",
       "      <td>12.072488</td>\n",
       "      <td>17.736907</td>\n",
       "      <td>10.480668</td>\n",
       "      <td>21.632934</td>\n",
       "      <td>11.405867</td>\n",
       "      <td>13.737130</td>\n",
       "      <td>5.901031</td>\n",
       "      <td>3.144239</td>\n",
       "      <td>19.324709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.464256</td>\n",
       "      <td>35.845605</td>\n",
       "      <td>105.298971</td>\n",
       "      <td>11.007412</td>\n",
       "      <td>104.764160</td>\n",
       "      <td>10.851210</td>\n",
       "      <td>0.305052</td>\n",
       "      <td>4.683480</td>\n",
       "      <td>7.461328</td>\n",
       "      <td>3.116574</td>\n",
       "      <td>...</td>\n",
       "      <td>6.064958</td>\n",
       "      <td>5.345290</td>\n",
       "      <td>7.085348</td>\n",
       "      <td>4.221941</td>\n",
       "      <td>4.519345</td>\n",
       "      <td>3.724047</td>\n",
       "      <td>4.536147</td>\n",
       "      <td>2.778302</td>\n",
       "      <td>2.628125</td>\n",
       "      <td>4.551727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1287.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1282.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1381.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Season         DayNum        WTeamID         WScore  \\\n",
       "count  116723.000000  116723.000000  116723.000000  116723.000000   \n",
       "mean     2014.051044      70.072462    1288.243422      75.859651   \n",
       "std         6.464256      35.845605     105.298971      11.007412   \n",
       "min      2003.000000       0.000000    1101.000000      34.000000   \n",
       "25%      2009.000000      38.000000    1199.000000      68.000000   \n",
       "50%      2014.000000      73.000000    1287.000000      75.000000   \n",
       "75%      2020.000000     101.000000    1381.000000      83.000000   \n",
       "max      2025.000000     132.000000    1480.000000     149.000000   \n",
       "\n",
       "             LTeamID         LScore          NumOT           WFGM  \\\n",
       "count  116723.000000  116723.000000  116723.000000  116723.000000   \n",
       "mean     1283.044987      63.857732       0.068658      26.392099   \n",
       "std       104.764160      10.851210       0.305052       4.683480   \n",
       "min      1101.000000      20.000000       0.000000      10.000000   \n",
       "25%      1192.000000      57.000000       0.000000      23.000000   \n",
       "50%      1282.000000      64.000000       0.000000      26.000000   \n",
       "75%      1374.000000      71.000000       0.000000      29.000000   \n",
       "max      1480.000000     144.000000       6.000000      57.000000   \n",
       "\n",
       "                WFGA          WFGM3  ...          LFGA3           LFTM  \\\n",
       "count  116723.000000  116723.000000  ...  116723.000000  116723.000000   \n",
       "mean       55.746305       7.339085  ...      20.138276      12.072488   \n",
       "std         7.461328       3.116574  ...       6.064958       5.345290   \n",
       "min        26.000000       0.000000  ...       1.000000       0.000000   \n",
       "25%        51.000000       5.000000  ...      16.000000       8.000000   \n",
       "50%        55.000000       7.000000  ...      20.000000      12.000000   \n",
       "75%        60.000000       9.000000  ...      24.000000      15.000000   \n",
       "max       103.000000      26.000000  ...      59.000000      48.000000   \n",
       "\n",
       "                LFTA            LOR            LDR           LAst  \\\n",
       "count  116723.000000  116723.000000  116723.000000  116723.000000   \n",
       "mean       17.736907      10.480668      21.632934      11.405867   \n",
       "std         7.085348       4.221941       4.519345       3.724047   \n",
       "min         0.000000       0.000000       4.000000       0.000000   \n",
       "25%        13.000000       7.000000      19.000000       9.000000   \n",
       "50%        17.000000      10.000000      21.000000      11.000000   \n",
       "75%        22.000000      13.000000      25.000000      14.000000   \n",
       "max        65.000000      36.000000      49.000000      31.000000   \n",
       "\n",
       "                 LTO           LStl           LBlk            LPF  \n",
       "count  116723.000000  116723.000000  116723.000000  116723.000000  \n",
       "mean       13.737130       5.901031       3.144239      19.324709  \n",
       "std         4.536147       2.778302       2.628125       4.551727  \n",
       "min         0.000000       0.000000       0.000000       4.000000  \n",
       "25%        11.000000       4.000000       1.000000      16.000000  \n",
       "50%        13.000000       6.000000       3.000000      19.000000  \n",
       "75%        17.000000       8.000000       4.000000      22.000000  \n",
       "max        41.000000      22.000000      33.000000      45.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mens = pd.read_csv('data/MRegularSeasonDetailedResults.csv')\n",
    "mens['League'] = 'M'\n",
    "mens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3be43b-6f29-44ab-bd21-55159ffe58be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017.310476</td>\n",
       "      <td>68.860759</td>\n",
       "      <td>3285.050867</td>\n",
       "      <td>71.711963</td>\n",
       "      <td>3286.594658</td>\n",
       "      <td>57.234370</td>\n",
       "      <td>0.051583</td>\n",
       "      <td>25.847537</td>\n",
       "      <td>58.980010</td>\n",
       "      <td>6.268876</td>\n",
       "      <td>...</td>\n",
       "      <td>17.913974</td>\n",
       "      <td>10.511119</td>\n",
       "      <td>15.515175</td>\n",
       "      <td>11.395447</td>\n",
       "      <td>22.441116</td>\n",
       "      <td>10.933688</td>\n",
       "      <td>16.745024</td>\n",
       "      <td>6.923831</td>\n",
       "      <td>3.434950</td>\n",
       "      <td>18.204184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.531798</td>\n",
       "      <td>36.258086</td>\n",
       "      <td>104.022507</td>\n",
       "      <td>11.547894</td>\n",
       "      <td>105.457243</td>\n",
       "      <td>10.964583</td>\n",
       "      <td>0.258755</td>\n",
       "      <td>4.982451</td>\n",
       "      <td>7.975729</td>\n",
       "      <td>3.125925</td>\n",
       "      <td>...</td>\n",
       "      <td>6.469817</td>\n",
       "      <td>4.938106</td>\n",
       "      <td>6.632564</td>\n",
       "      <td>4.639725</td>\n",
       "      <td>4.939763</td>\n",
       "      <td>3.805204</td>\n",
       "      <td>5.597689</td>\n",
       "      <td>3.279905</td>\n",
       "      <td>3.666537</td>\n",
       "      <td>4.557235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3101.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3101.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3196.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3195.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>3283.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>3287.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>3376.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3377.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Season        DayNum       WTeamID        WScore       LTeamID  \\\n",
       "count  79639.000000  79639.000000  79639.000000  79639.000000  79639.000000   \n",
       "mean    2017.310476     68.860759   3285.050867     71.711963   3286.594658   \n",
       "std        4.531798     36.258086    104.022507     11.547894    105.457243   \n",
       "min     2010.000000      0.000000   3101.000000     30.000000   3101.000000   \n",
       "25%     2013.000000     35.000000   3196.000000     64.000000   3195.000000   \n",
       "50%     2017.000000     72.000000   3283.000000     71.000000   3287.000000   \n",
       "75%     2021.000000    101.000000   3376.000000     79.000000   3377.000000   \n",
       "max     2025.000000    132.000000   3480.000000    140.000000   3480.000000   \n",
       "\n",
       "             LScore         NumOT          WFGM          WFGA         WFGM3  \\\n",
       "count  79639.000000  79639.000000  79639.000000  79639.000000  79639.000000   \n",
       "mean      57.234370      0.051583     25.847537     58.980010      6.268876   \n",
       "std       10.964583      0.258755      4.982451      7.975729      3.125925   \n",
       "min       11.000000      0.000000      9.000000     30.000000      0.000000   \n",
       "25%       50.000000      0.000000     22.000000     53.000000      4.000000   \n",
       "50%       57.000000      0.000000     25.000000     59.000000      6.000000   \n",
       "75%       64.000000      0.000000     29.000000     64.000000      8.000000   \n",
       "max      130.000000      5.000000     58.000000    113.000000     30.000000   \n",
       "\n",
       "       ...         LFGA3          LFTM          LFTA           LOR  \\\n",
       "count  ...  79639.000000  79639.000000  79639.000000  79639.000000   \n",
       "mean   ...     17.913974     10.511119     15.515175     11.395447   \n",
       "std    ...      6.469817      4.938106      6.632564      4.639725   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...     13.000000      7.000000     11.000000      8.000000   \n",
       "50%    ...     17.000000     10.000000     15.000000     11.000000   \n",
       "75%    ...     22.000000     14.000000     20.000000     14.000000   \n",
       "max    ...     80.000000     37.000000     52.000000     38.000000   \n",
       "\n",
       "                LDR          LAst           LTO          LStl          LBlk  \\\n",
       "count  79639.000000  79639.000000  79639.000000  79639.000000  79639.000000   \n",
       "mean      22.441116     10.933688     16.745024      6.923831      3.434950   \n",
       "std        4.939763      3.805204      5.597689      3.279905      3.666537   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       19.000000      8.000000     13.000000      5.000000      1.000000   \n",
       "50%       22.000000     11.000000     16.000000      7.000000      3.000000   \n",
       "75%       26.000000     13.000000     20.000000      9.000000      4.000000   \n",
       "max       53.000000     34.000000     49.000000     26.000000     42.000000   \n",
       "\n",
       "                LPF  \n",
       "count  79639.000000  \n",
       "mean      18.204184  \n",
       "std        4.557235  \n",
       "min        3.000000  \n",
       "25%       15.000000  \n",
       "50%       18.000000  \n",
       "75%       21.000000  \n",
       "max       47.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womens = pd.read_csv('data/WRegularSeasonDetailedResults.csv')\n",
    "womens['League'] = 'W'\n",
    "womens.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a57ce-cca2-4b81-a8a2-ad8638faefbe",
   "metadata": {},
   "source": [
    "The IDs are definitely distinct so we can combine into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c18b78-f8fb-439f-bdeb-079abb4516f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = pd.concat([mens, womens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6210e5c-c7a9-4ec3-95f6-b4a963a6d191",
   "metadata": {},
   "source": [
    "Get the distinct team/Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2206f762-b26b-49a2-b97a-94929f7273e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat([all_teams[['WTeamID', 'Season', 'League']].rename(columns={'WTeamID': 'TeamID'}),\n",
    "                   all_teams[['LTeamID', 'Season', 'League']].rename(columns={'LTeamID': 'TeamID'})]).drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee119045-207e-4dae-9ec7-1ef186642f48",
   "metadata": {},
   "source": [
    "Define the training data. The x's will be the indexes of two team IDs, the y's will be 1 if the first team won, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607aaaf7-13f0-461e-8b2a-7477c1f57bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teamMapping = {(x.TeamID, x.Season): x.Index for x in teams.itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d52abd-7d74-4996-a93b-ab2e578bdf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>League</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79634</th>\n",
       "      <td>2025</td>\n",
       "      <td>84</td>\n",
       "      <td>3450</td>\n",
       "      <td>65</td>\n",
       "      <td>3333</td>\n",
       "      <td>57</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79635</th>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>3129</td>\n",
       "      <td>89</td>\n",
       "      <td>3307</td>\n",
       "      <td>80</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79636</th>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>3234</td>\n",
       "      <td>85</td>\n",
       "      <td>3321</td>\n",
       "      <td>80</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79637</th>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>3337</td>\n",
       "      <td>55</td>\n",
       "      <td>3258</td>\n",
       "      <td>43</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79638</th>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>3475</td>\n",
       "      <td>72</td>\n",
       "      <td>3287</td>\n",
       "      <td>52</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196362 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  \\\n",
       "0        2003      10     1104      68     1328      62    N      0    27   \n",
       "1        2003      10     1272      70     1393      63    N      0    26   \n",
       "2        2003      11     1266      73     1437      61    N      0    24   \n",
       "3        2003      11     1296      56     1457      50    N      0    18   \n",
       "4        2003      11     1400      77     1208      71    N      0    30   \n",
       "...       ...     ...      ...     ...      ...     ...  ...    ...   ...   \n",
       "79634    2025      84     3450      65     3333      57    A      0    24   \n",
       "79635    2025      85     3129      89     3307      80    H      0    33   \n",
       "79636    2025      85     3234      85     3321      80    H      0    29   \n",
       "79637    2025      85     3337      55     3258      43    H      0    21   \n",
       "79638    2025      85     3475      72     3287      52    A      0    26   \n",
       "\n",
       "       WFGA  ...  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  League  \n",
       "0        58  ...    16    22   10   22     8   18     9     2   20       M  \n",
       "1        62  ...     9    20   20   25     7   12     8     6   16       M  \n",
       "2        58  ...    14    23   31   22     9   12     2     5   23       M  \n",
       "3        38  ...     8    15   17   20     9   19     4     3   23       M  \n",
       "4        61  ...    17    27   21   15    12   10     7     1   14       M  \n",
       "...     ...  ...   ...   ...  ...  ...   ...  ...   ...   ...  ...     ...  \n",
       "79634    58  ...     7     9   11   23    10    8     5    10   14       W  \n",
       "79635    73  ...     7    16    4   25    16    4     2    13   13       W  \n",
       "79636    60  ...    13    20    6   25    18    8     2    13   21       W  \n",
       "79637    50  ...    14    17   11   20     6    8     2    10   13       W  \n",
       "79638    52  ...     8    10    9   14     8   10     6    21   16       W  \n",
       "\n",
       "[196362 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f2c1e7-5289-431c-a2e4-50fea2c15249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(data):\n",
    "    winners = data.apply(lambda x: teamMapping[(x.WTeamID, x.Season)], axis=1)\n",
    "    losers = data.apply(lambda x: teamMapping[(x.LTeamID, x.Season)], axis=1)\n",
    "    x_tensor = torch.from_numpy(np.concatenate([np.stack([winners, losers], axis=1), np.stack([losers, winners], axis=1)]))\n",
    "    y_tensor = torch.from_numpy(np.concatenate([np.stack([data.WScore, data.LScore]),\n",
    "                                                np.stack([data.LScore, data.WScore])], axis=1).transpose()).double()\n",
    "    return TensorDataset(x_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57ad178-fdaf-4e87-a0b7-959876a5d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = gen_dataset(all_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e570534-09f4-4e6a-b9bd-e77e52014ce5",
   "metadata": {},
   "source": [
    "Generate the train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbc8b7f-0b20-4f49-92e9-f16cadfeeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "\n",
    "generator = torch.Generator().manual_seed(20250217)\n",
    "train_data, validation_data = torch.utils.data.random_split(dataset, [0.9, 0.1], generator=generator)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50ea84-42ce-462c-a3b3-3928a04aa7ef",
   "metadata": {},
   "source": [
    "## The Model\n",
    "Define the model. Combine the embeddings for the two teams, go to a hidden layer, and then output to a prediction if the first team won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5dbb96c-d80f-454e-bdda-f2d9eadd3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_size=64, model_size=16, dropout=0.1):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(teams), embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(2*embedding_size, model_size)\n",
    "        self.score_fc = nn.Linear(model_size, 1)\n",
    "        self.opponent_fc = nn.Linear(model_size, 1)\n",
    "        self.result_fc = nn.Linear(model_size, 1)\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        team = self.embedding(x[:,0])\n",
    "        opponent = self.embedding(x[:,1])\n",
    "        matchup = torch.cat([team, opponent], axis=1)\n",
    "        hidden = self.dropout(F.relu(self.fc1(matchup)))\n",
    "        score = self.score_fc(hidden)\n",
    "        opponent_score = self.opponent_fc(hidden)\n",
    "        result = F.sigmoid(self.result_fc(hidden))\n",
    "        return score, opponent_score, result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5629261-0b6d-44c9-828e-698e86006f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(embedding_size=128, model_size=64, dropout=0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98325a-8ba0-466f-b3ca-6991e8450a08",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cb92ad-908f-44a7-a2a0-88dd9d4d51ab",
   "metadata": {},
   "source": [
    "Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab2ee77-d1dd-444f-b7bc-b5e7d057ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "def train(data, model, loss_fn, optimizer, full_loss=True):\n",
    "    size = len(data.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(data):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred_score, pred_opponent, pred_result = model(x)\n",
    "        actual_score = y[:,0].reshape([-1,1])\n",
    "        actual_opponent = y[:,1].reshape([-1,1])\n",
    "        actual_result = (actual_score > actual_opponent).double().reshape([-1,1])\n",
    "        score_loss = loss_fn(pred_score, actual_score)\n",
    "        opponent_loss = loss_fn(pred_opponent, actual_opponent)\n",
    "        result_loss = loss_fn(pred_result, actual_result)\n",
    "        if full_loss:\n",
    "            (score_loss + opponent_loss + 10 * result_loss).backward()\n",
    "        else:\n",
    "            result_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            score_loss, result_loss, current = score_loss.item(), result_loss.item(), (batch + 1) * len(x)\n",
    "            print(f\"score loss: {score_loss:>7f}, opp loss: {opponent_loss:>7f}, result loss: {result_loss:>7f} [{current:>6d}/{size:>6d}]\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadb0b3-4e99-47a2-8fee-846467b01b86",
   "metadata": {},
   "source": [
    "Define the testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3466d44f-fc82-46a7-95e1-0590674e7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, model, loss_fn, label=\"Test\"):\n",
    "    size = len(data.dataset)\n",
    "    num_batches = len(data)\n",
    "    model.eval()\n",
    "    score_loss, opponent_loss, result_loss, correct = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            score_pred, pred_opponent, result_pred = model(x)\n",
    "            actual_score = y[:,0].reshape([-1,1])\n",
    "            actual_opponent = y[:,1].reshape([-1,1])\n",
    "            actual_result = (actual_score > actual_opponent).double().reshape([-1,1])\n",
    "\n",
    "            score_loss += loss_fn(score_pred, actual_score).item()\n",
    "            opponent_loss += loss_fn(pred_opponent, actual_opponent).item()\n",
    "            result_loss += loss_fn(result_pred, actual_result)\n",
    "            correct += ((result_pred >= 0.5) == (actual_result == 1)).type(torch.float).sum().item()\n",
    "    score_loss /= num_batches\n",
    "    opponent_loss /= num_batches\n",
    "    result_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"{label}: Accuracy: {(100*correct):>0.1f}%, Score loss: {score_loss:>8f}, Opp loss: {opponent_loss:>8f}, Result loss: {result_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fca87-08c7-48e0-92dd-52ef4ff8463f",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fba01505-0d95-404d-802a-e4922ab226a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train: Accuracy: 50.1%, Score loss: 180.392454, Opp loss: 180.417587, Result loss: 0.250112\n",
      "Validation: Accuracy: 50.3%, Score loss: 181.407413, Opp loss: 182.369613, Result loss: 0.250048\n",
      "Epoch 1\n",
      "Train: Accuracy: 50.1%, Score loss: 173.199627, Opp loss: 173.149636, Result loss: 0.250101\n",
      "Validation: Accuracy: 50.3%, Score loss: 174.593644, Opp loss: 175.554610, Result loss: 0.250067\n",
      "Epoch 2\n",
      "Train: Accuracy: 50.1%, Score loss: 169.687883, Opp loss: 169.882760, Result loss: 0.250153\n",
      "Validation: Accuracy: 50.1%, Score loss: 171.397239, Opp loss: 172.508619, Result loss: 0.250101\n",
      "Epoch 3\n",
      "Train: Accuracy: 50.0%, Score loss: 168.259443, Opp loss: 168.464083, Result loss: 0.250166\n",
      "Validation: Accuracy: 50.1%, Score loss: 169.876358, Opp loss: 170.868079, Result loss: 0.250123\n",
      "Epoch 4\n",
      "Train: Accuracy: 50.0%, Score loss: 165.885835, Opp loss: 166.201830, Result loss: 0.250245\n",
      "Validation: Accuracy: 50.0%, Score loss: 167.605000, Opp loss: 168.666883, Result loss: 0.250260\n",
      "Epoch 5\n",
      "Train: Accuracy: 50.0%, Score loss: 162.856437, Opp loss: 163.177669, Result loss: 0.250294\n",
      "Validation: Accuracy: 50.0%, Score loss: 165.025591, Opp loss: 165.625360, Result loss: 0.250270\n",
      "Epoch 6\n",
      "Train: Accuracy: 50.0%, Score loss: 156.951829, Opp loss: 157.261224, Result loss: 0.250326\n",
      "Validation: Accuracy: 50.0%, Score loss: 159.579239, Opp loss: 160.442491, Result loss: 0.250385\n",
      "Epoch 7\n",
      "Train: Accuracy: 50.0%, Score loss: 150.247922, Opp loss: 150.596048, Result loss: 0.250316\n",
      "Validation: Accuracy: 50.0%, Score loss: 153.421215, Opp loss: 154.258361, Result loss: 0.250308\n",
      "Epoch 8\n",
      "Train: Accuracy: 50.0%, Score loss: 143.696058, Opp loss: 144.045269, Result loss: 0.250590\n",
      "Validation: Accuracy: 50.0%, Score loss: 147.684771, Opp loss: 148.382701, Result loss: 0.250585\n",
      "Epoch 9\n",
      "Train: Accuracy: 50.0%, Score loss: 138.519130, Opp loss: 138.881156, Result loss: 0.250374\n",
      "Validation: Accuracy: 50.0%, Score loss: 143.049599, Opp loss: 143.626408, Result loss: 0.250357\n",
      "Epoch 10\n",
      "Train: Accuracy: 50.0%, Score loss: 134.573823, Opp loss: 135.010916, Result loss: 0.250509\n",
      "Validation: Accuracy: 50.0%, Score loss: 139.365672, Opp loss: 140.082224, Result loss: 0.250485\n",
      "Epoch 11\n",
      "Train: Accuracy: 50.0%, Score loss: 132.476443, Opp loss: 132.826188, Result loss: 0.250353\n",
      "Validation: Accuracy: 50.0%, Score loss: 137.674745, Opp loss: 138.041728, Result loss: 0.250345\n",
      "Epoch 12\n",
      "Train: Accuracy: 50.0%, Score loss: 131.264864, Opp loss: 131.789849, Result loss: 0.250379\n",
      "Validation: Accuracy: 50.0%, Score loss: 136.378266, Opp loss: 137.063087, Result loss: 0.250372\n",
      "Epoch 13\n",
      "Train: Accuracy: 50.0%, Score loss: 130.646048, Opp loss: 131.112170, Result loss: 0.250464\n",
      "Validation: Accuracy: 50.0%, Score loss: 135.783921, Opp loss: 136.638791, Result loss: 0.250448\n",
      "Epoch 14\n",
      "Train: Accuracy: 50.0%, Score loss: 130.182215, Opp loss: 130.644905, Result loss: 0.250376\n",
      "Validation: Accuracy: 50.0%, Score loss: 135.246304, Opp loss: 136.149482, Result loss: 0.250354\n",
      "Epoch 15\n",
      "Train: Accuracy: 50.0%, Score loss: 129.663516, Opp loss: 129.979066, Result loss: 0.250458\n",
      "Validation: Accuracy: 50.0%, Score loss: 134.873256, Opp loss: 135.414162, Result loss: 0.250451\n",
      "Epoch 16\n",
      "Train: Accuracy: 50.0%, Score loss: 129.779568, Opp loss: 130.257367, Result loss: 0.250440\n",
      "Validation: Accuracy: 50.0%, Score loss: 134.935643, Opp loss: 135.722926, Result loss: 0.250431\n",
      "Epoch 17\n",
      "Train: Accuracy: 50.0%, Score loss: 129.115154, Opp loss: 129.864634, Result loss: 0.250320\n",
      "Validation: Accuracy: 50.0%, Score loss: 134.413412, Opp loss: 135.496593, Result loss: 0.250308\n",
      "Epoch 18\n",
      "Train: Accuracy: 50.0%, Score loss: 129.205079, Opp loss: 129.616929, Result loss: 0.250298\n",
      "Validation: Accuracy: 50.0%, Score loss: 134.482927, Opp loss: 135.025440, Result loss: 0.250288\n",
      "Epoch 19\n",
      "Train: Accuracy: 50.0%, Score loss: 129.004775, Opp loss: 129.377606, Result loss: 0.250300\n",
      "Validation: Accuracy: 50.0%, Score loss: 134.324435, Opp loss: 134.960190, Result loss: 0.250292\n",
      "Epoch 20\n",
      "Train: Accuracy: 50.0%, Score loss: 129.213277, Opp loss: 129.375412, Result loss: 0.250252\n",
      "Validation: Accuracy: 50.0%, Score loss: 134.516108, Opp loss: 134.930770, Result loss: 0.250259\n",
      "Epoch 21\n",
      "Train: Accuracy: 50.0%, Score loss: 128.650957, Opp loss: 129.308670, Result loss: 0.249875\n",
      "Validation: Accuracy: 50.1%, Score loss: 133.995977, Opp loss: 134.864450, Result loss: 0.249887\n",
      "Epoch 22\n",
      "Train: Accuracy: 50.1%, Score loss: 128.601264, Opp loss: 129.165171, Result loss: 0.249837\n",
      "Validation: Accuracy: 50.1%, Score loss: 133.888596, Opp loss: 134.625765, Result loss: 0.249860\n",
      "Epoch 23\n",
      "Train: Accuracy: 50.5%, Score loss: 128.419740, Opp loss: 129.276642, Result loss: 0.249348\n",
      "Validation: Accuracy: 50.4%, Score loss: 133.662637, Opp loss: 134.652431, Result loss: 0.249402\n",
      "Epoch 24\n",
      "Train: Accuracy: 51.6%, Score loss: 128.228859, Opp loss: 128.972597, Result loss: 0.248679\n",
      "Validation: Accuracy: 51.3%, Score loss: 133.569452, Opp loss: 134.400446, Result loss: 0.248758\n",
      "Epoch 25\n",
      "Train: Accuracy: 54.6%, Score loss: 127.371423, Opp loss: 127.999510, Result loss: 0.246847\n",
      "Validation: Accuracy: 54.2%, Score loss: 132.867942, Opp loss: 133.575962, Result loss: 0.246976\n",
      "Epoch 26\n",
      "Train: Accuracy: 56.2%, Score loss: 126.319941, Opp loss: 127.178899, Result loss: 0.244465\n",
      "Validation: Accuracy: 56.0%, Score loss: 131.964365, Opp loss: 132.784931, Result loss: 0.244746\n",
      "Epoch 27\n",
      "Train: Accuracy: 58.4%, Score loss: 124.576673, Opp loss: 125.174006, Result loss: 0.240218\n",
      "Validation: Accuracy: 58.1%, Score loss: 130.295214, Opp loss: 130.961592, Result loss: 0.240876\n",
      "Epoch 28\n",
      "Train: Accuracy: 61.0%, Score loss: 122.055549, Opp loss: 122.784524, Result loss: 0.233457\n",
      "Validation: Accuracy: 60.6%, Score loss: 128.148291, Opp loss: 128.890868, Result loss: 0.234761\n",
      "Epoch 29\n",
      "Train: Accuracy: 63.4%, Score loss: 118.611110, Opp loss: 119.232009, Result loss: 0.224595\n",
      "Validation: Accuracy: 62.8%, Score loss: 125.105363, Opp loss: 125.751163, Result loss: 0.226926\n",
      "Epoch 30\n",
      "Train: Accuracy: 65.8%, Score loss: 114.458016, Opp loss: 114.929149, Result loss: 0.214667\n",
      "Validation: Accuracy: 64.7%, Score loss: 121.616563, Opp loss: 121.885852, Result loss: 0.218178\n",
      "Epoch 31\n",
      "Train: Accuracy: 68.3%, Score loss: 109.972709, Opp loss: 110.352636, Result loss: 0.203515\n",
      "Validation: Accuracy: 67.1%, Score loss: 117.458190, Opp loss: 117.728073, Result loss: 0.208178\n",
      "Epoch 32\n",
      "Train: Accuracy: 70.3%, Score loss: 106.104655, Opp loss: 106.149151, Result loss: 0.193064\n",
      "Validation: Accuracy: 68.7%, Score loss: 113.954617, Opp loss: 113.986104, Result loss: 0.198795\n",
      "Epoch 33\n",
      "Train: Accuracy: 72.0%, Score loss: 102.212841, Opp loss: 102.444408, Result loss: 0.184416\n",
      "Validation: Accuracy: 70.2%, Score loss: 110.343999, Opp loss: 110.410221, Result loss: 0.190927\n",
      "Epoch 34\n",
      "Train: Accuracy: 73.2%, Score loss: 99.238711, Opp loss: 98.938104, Result loss: 0.177153\n",
      "Validation: Accuracy: 71.6%, Score loss: 107.713355, Opp loss: 107.304528, Result loss: 0.184180\n",
      "Epoch 35\n",
      "Train: Accuracy: 74.2%, Score loss: 97.005513, Opp loss: 96.908894, Result loss: 0.171795\n",
      "Validation: Accuracy: 72.4%, Score loss: 105.540716, Opp loss: 105.224499, Result loss: 0.179216\n",
      "Epoch 36\n",
      "Train: Accuracy: 75.0%, Score loss: 95.657359, Opp loss: 95.690170, Result loss: 0.167434\n",
      "Validation: Accuracy: 73.3%, Score loss: 104.126948, Opp loss: 103.961535, Result loss: 0.174892\n",
      "Epoch 37\n",
      "Train: Accuracy: 75.6%, Score loss: 94.154123, Opp loss: 94.293808, Result loss: 0.164338\n",
      "Validation: Accuracy: 73.9%, Score loss: 102.700565, Opp loss: 102.465119, Result loss: 0.171791\n",
      "Epoch 38\n",
      "Train: Accuracy: 75.9%, Score loss: 93.284379, Opp loss: 93.388005, Result loss: 0.162314\n",
      "Validation: Accuracy: 74.3%, Score loss: 101.906962, Opp loss: 101.693450, Result loss: 0.169922\n",
      "Epoch 39\n",
      "Train: Accuracy: 76.1%, Score loss: 92.699820, Opp loss: 92.731131, Result loss: 0.161032\n",
      "Validation: Accuracy: 74.6%, Score loss: 101.255400, Opp loss: 100.972584, Result loss: 0.168498\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Epoch {i}\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(train_loader, model, loss_fn, label=\"Train\")\n",
    "    test(validation_loader, model, loss_fn, label=\"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aaf28c-130c-4579-a627-7475f7abc2a2",
   "metadata": {},
   "source": [
    "Fine tune with only the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4074860-e773-4900-96d3-7859687f15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train: Accuracy: 76.6%, Score loss: 111.406612, Opp loss: 112.660213, Result loss: 0.157540\n",
      "Validation: Accuracy: 74.8%, Score loss: 118.949572, Opp loss: 119.854813, Result loss: 0.167028\n",
      "Epoch 1\n",
      "Train: Accuracy: 77.3%, Score loss: 216.279735, Opp loss: 215.277332, Result loss: 0.154228\n",
      "Validation: Accuracy: 75.2%, Score loss: 221.524202, Opp loss: 220.637819, Result loss: 0.166152\n",
      "Epoch 2\n",
      "Train: Accuracy: 77.7%, Score loss: 317.222048, Opp loss: 312.317956, Result loss: 0.152352\n",
      "Validation: Accuracy: 75.4%, Score loss: 321.193581, Opp loss: 316.775677, Result loss: 0.165958\n",
      "Epoch 3\n",
      "Train: Accuracy: 78.0%, Score loss: 382.839324, Opp loss: 376.303874, Result loss: 0.151404\n",
      "Validation: Accuracy: 75.4%, Score loss: 386.157730, Opp loss: 380.358443, Result loss: 0.166126\n",
      "Epoch 4\n",
      "Train: Accuracy: 78.1%, Score loss: 429.388091, Opp loss: 423.020892, Result loss: 0.150812\n",
      "Validation: Accuracy: 75.5%, Score loss: 432.368702, Opp loss: 426.988458, Result loss: 0.166350\n",
      "Epoch 5\n",
      "Train: Accuracy: 78.3%, Score loss: 466.859586, Opp loss: 457.040485, Result loss: 0.150454\n",
      "Validation: Accuracy: 75.5%, Score loss: 469.648420, Opp loss: 461.170479, Result loss: 0.166623\n",
      "Epoch 6\n",
      "Train: Accuracy: 78.4%, Score loss: 487.442938, Opp loss: 474.776924, Result loss: 0.150216\n",
      "Validation: Accuracy: 75.5%, Score loss: 490.183599, Opp loss: 479.237919, Result loss: 0.166851\n",
      "Epoch 7\n",
      "Train: Accuracy: 78.5%, Score loss: 507.199006, Opp loss: 493.654072, Result loss: 0.149902\n",
      "Validation: Accuracy: 75.5%, Score loss: 509.792528, Opp loss: 498.254988, Result loss: 0.166923\n",
      "Epoch 8\n",
      "Train: Accuracy: 78.6%, Score loss: 524.049933, Opp loss: 508.746387, Result loss: 0.149722\n",
      "Validation: Accuracy: 75.6%, Score loss: 526.713140, Opp loss: 513.655418, Result loss: 0.167149\n",
      "Epoch 9\n",
      "Train: Accuracy: 78.6%, Score loss: 541.932481, Opp loss: 524.058910, Result loss: 0.149565\n",
      "Validation: Accuracy: 75.6%, Score loss: 544.506702, Opp loss: 529.094750, Result loss: 0.167156\n",
      "Epoch 10\n",
      "Train: Accuracy: 78.7%, Score loss: 559.766169, Opp loss: 540.557816, Result loss: 0.149371\n",
      "Validation: Accuracy: 75.6%, Score loss: 561.962533, Opp loss: 545.740778, Result loss: 0.167306\n",
      "Epoch 11\n",
      "Train: Accuracy: 78.8%, Score loss: 579.325031, Opp loss: 561.006912, Result loss: 0.149221\n",
      "Validation: Accuracy: 75.6%, Score loss: 581.419873, Opp loss: 566.391196, Result loss: 0.167231\n",
      "Epoch 12\n",
      "Train: Accuracy: 78.8%, Score loss: 603.491632, Opp loss: 581.769055, Result loss: 0.149008\n",
      "Validation: Accuracy: 75.6%, Score loss: 605.113824, Opp loss: 587.260368, Result loss: 0.167334\n",
      "Epoch 13\n",
      "Train: Accuracy: 78.8%, Score loss: 629.925175, Opp loss: 607.061133, Result loss: 0.148809\n",
      "Validation: Accuracy: 75.6%, Score loss: 630.985013, Opp loss: 612.576467, Result loss: 0.167260\n",
      "Epoch 14\n",
      "Train: Accuracy: 78.9%, Score loss: 658.649883, Opp loss: 632.723098, Result loss: 0.148569\n",
      "Validation: Accuracy: 75.6%, Score loss: 659.207569, Opp loss: 638.265437, Result loss: 0.167356\n",
      "Epoch 15\n",
      "Train: Accuracy: 78.9%, Score loss: 692.234834, Opp loss: 664.063369, Result loss: 0.148376\n",
      "Validation: Accuracy: 75.5%, Score loss: 692.124919, Opp loss: 669.478368, Result loss: 0.167416\n",
      "Epoch 16\n",
      "Train: Accuracy: 79.0%, Score loss: 726.444493, Opp loss: 696.641188, Result loss: 0.148006\n",
      "Validation: Accuracy: 75.6%, Score loss: 725.762933, Opp loss: 702.057395, Result loss: 0.167166\n",
      "Epoch 17\n",
      "Train: Accuracy: 79.0%, Score loss: 763.357023, Opp loss: 731.196107, Result loss: 0.147717\n",
      "Validation: Accuracy: 75.6%, Score loss: 762.191661, Opp loss: 736.670082, Result loss: 0.167181\n",
      "Epoch 18\n",
      "Train: Accuracy: 79.0%, Score loss: 801.666269, Opp loss: 767.154338, Result loss: 0.147347\n",
      "Validation: Accuracy: 75.6%, Score loss: 799.702348, Opp loss: 772.746519, Result loss: 0.167119\n",
      "Epoch 19\n",
      "Train: Accuracy: 79.0%, Score loss: 843.935919, Opp loss: 807.026464, Result loss: 0.146971\n",
      "Validation: Accuracy: 75.6%, Score loss: 841.478419, Opp loss: 812.678746, Result loss: 0.167086\n",
      "Epoch 20\n",
      "Train: Accuracy: 79.0%, Score loss: 892.196829, Opp loss: 852.074544, Result loss: 0.146573\n",
      "Validation: Accuracy: 75.7%, Score loss: 889.024622, Opp loss: 857.969105, Result loss: 0.166952\n",
      "Epoch 21\n",
      "Train: Accuracy: 79.0%, Score loss: 942.566598, Opp loss: 899.201762, Result loss: 0.146154\n",
      "Validation: Accuracy: 75.6%, Score loss: 938.848377, Opp loss: 905.520940, Result loss: 0.166932\n",
      "Epoch 22\n",
      "Train: Accuracy: 79.0%, Score loss: 996.341327, Opp loss: 950.435161, Result loss: 0.145801\n",
      "Validation: Accuracy: 75.6%, Score loss: 992.390738, Opp loss: 957.607363, Result loss: 0.166815\n",
      "Epoch 23\n",
      "Train: Accuracy: 79.0%, Score loss: 1053.046888, Opp loss: 1005.021173, Result loss: 0.145348\n",
      "Validation: Accuracy: 75.6%, Score loss: 1049.027155, Opp loss: 1012.892067, Result loss: 0.166863\n",
      "Epoch 24\n",
      "Train: Accuracy: 79.0%, Score loss: 1114.132995, Opp loss: 1061.936819, Result loss: 0.144883\n",
      "Validation: Accuracy: 75.7%, Score loss: 1109.686740, Opp loss: 1070.475654, Result loss: 0.166790\n",
      "Epoch 25\n",
      "Train: Accuracy: 79.0%, Score loss: 1175.604855, Opp loss: 1119.074396, Result loss: 0.144524\n",
      "Validation: Accuracy: 75.7%, Score loss: 1170.821917, Opp loss: 1128.464298, Result loss: 0.166590\n",
      "Epoch 26\n",
      "Train: Accuracy: 79.0%, Score loss: 1240.325755, Opp loss: 1180.562423, Result loss: 0.144080\n",
      "Validation: Accuracy: 75.7%, Score loss: 1235.479020, Opp loss: 1190.840174, Result loss: 0.166667\n",
      "Epoch 27\n",
      "Train: Accuracy: 79.0%, Score loss: 1303.163533, Opp loss: 1240.853288, Result loss: 0.143779\n",
      "Validation: Accuracy: 75.7%, Score loss: 1298.445280, Opp loss: 1252.458466, Result loss: 0.166607\n",
      "Epoch 28\n",
      "Train: Accuracy: 79.0%, Score loss: 1369.032167, Opp loss: 1302.742038, Result loss: 0.143534\n",
      "Validation: Accuracy: 75.7%, Score loss: 1364.703320, Opp loss: 1315.601195, Result loss: 0.166558\n",
      "Epoch 29\n",
      "Train: Accuracy: 79.1%, Score loss: 1432.770434, Opp loss: 1362.910674, Result loss: 0.143106\n",
      "Validation: Accuracy: 75.7%, Score loss: 1428.611907, Opp loss: 1377.280660, Result loss: 0.166504\n",
      "Epoch 30\n",
      "Train: Accuracy: 79.1%, Score loss: 1492.683170, Opp loss: 1420.044968, Result loss: 0.142694\n",
      "Validation: Accuracy: 75.7%, Score loss: 1489.148327, Opp loss: 1435.887415, Result loss: 0.166377\n",
      "Epoch 31\n",
      "Train: Accuracy: 79.1%, Score loss: 1551.870845, Opp loss: 1475.034346, Result loss: 0.142318\n",
      "Validation: Accuracy: 75.7%, Score loss: 1549.012725, Opp loss: 1492.282069, Result loss: 0.166388\n",
      "Epoch 32\n",
      "Train: Accuracy: 79.1%, Score loss: 1605.450376, Opp loss: 1526.224903, Result loss: 0.141940\n",
      "Validation: Accuracy: 75.7%, Score loss: 1602.993062, Opp loss: 1544.843379, Result loss: 0.166288\n",
      "Epoch 33\n",
      "Train: Accuracy: 79.1%, Score loss: 1651.410268, Opp loss: 1572.577677, Result loss: 0.141860\n",
      "Validation: Accuracy: 75.7%, Score loss: 1649.796959, Opp loss: 1592.976260, Result loss: 0.166379\n",
      "Epoch 34\n",
      "Train: Accuracy: 79.1%, Score loss: 1692.685294, Opp loss: 1611.614528, Result loss: 0.141574\n",
      "Validation: Accuracy: 75.6%, Score loss: 1691.598415, Opp loss: 1633.823375, Result loss: 0.166442\n",
      "Epoch 35\n",
      "Train: Accuracy: 79.1%, Score loss: 1728.428040, Opp loss: 1644.088583, Result loss: 0.141094\n",
      "Validation: Accuracy: 75.5%, Score loss: 1727.862401, Opp loss: 1667.399618, Result loss: 0.166208\n",
      "Epoch 36\n",
      "Train: Accuracy: 79.1%, Score loss: 1753.338610, Opp loss: 1669.659497, Result loss: 0.140871\n",
      "Validation: Accuracy: 75.7%, Score loss: 1753.581323, Opp loss: 1694.555921, Result loss: 0.166109\n",
      "Epoch 37\n",
      "Train: Accuracy: 79.1%, Score loss: 1772.347331, Opp loss: 1683.898325, Result loss: 0.140529\n",
      "Validation: Accuracy: 75.7%, Score loss: 1773.377090, Opp loss: 1709.778063, Result loss: 0.166124\n",
      "Epoch 38\n",
      "Train: Accuracy: 79.2%, Score loss: 1779.055394, Opp loss: 1693.053180, Result loss: 0.140251\n",
      "Validation: Accuracy: 75.7%, Score loss: 1781.066435, Opp loss: 1720.046946, Result loss: 0.166066\n",
      "Epoch 39\n",
      "Train: Accuracy: 79.3%, Score loss: 1778.247022, Opp loss: 1692.789335, Result loss: 0.139994\n",
      "Validation: Accuracy: 75.6%, Score loss: 1781.219771, Opp loss: 1720.785181, Result loss: 0.166028\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    print(f\"Epoch {i}\")\n",
    "    train(train_loader, model, loss_fn, optimizer, full_loss=False)\n",
    "    test(train_loader, model, loss_fn, label=\"Train\")\n",
    "    test(validation_loader, model, loss_fn, label=\"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55a843-9fa3-443f-8342-410abd74688c",
   "metadata": {},
   "source": [
    "With this model we can predict the output of about three quarters of regular season games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe60ad-2cd9-4339-9600-62264350e6bd",
   "metadata": {},
   "source": [
    "## Load the tourney data to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093fcd61-386e-4330-b5af-e9d93df1b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "mens_tourney = pd.read_csv('data/MNCAATourneyDetailedResults.csv')\n",
    "womens_tourney = pd.read_csv('data/WNCAATourneyDetailedResults.csv')\n",
    "tourney = pd.concat([mens_tourney, womens_tourney])\n",
    "\n",
    "tourney_dataset = gen_dataset(tourney)\n",
    "tourney_loader = DataLoader(tourney_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08340cd1-6cb0-400a-80fa-dda1171789bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tourney: Accuracy: 69.3%, Score loss: 2197.340647, Opp loss: 2195.927133, Result loss: 0.205475\n"
     ]
    }
   ],
   "source": [
    "test(tourney_loader, model, loss_fn, label=\"Tourney\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7c18a-8267-4926-a191-5c3a218bfde2",
   "metadata": {},
   "source": [
    "When it comes to tournament results we get about 7 out of 10 results. The lower result is likely due to teams having increased pairity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8ba4d-cd61-4693-9cda-963ecca19c07",
   "metadata": {},
   "source": [
    "### Performance by year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fda1ddd2-af9c-4bed-9812-fc24e0c56d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003 Tournament: Accuracy: 64.8%, Score loss: 1173.754300, Opp loss: 1165.858977, Result loss: 0.229128\n",
      "2004 Tournament: Accuracy: 71.1%, Score loss: 1828.464633, Opp loss: 1802.155607, Result loss: 0.218459\n",
      "2005 Tournament: Accuracy: 70.3%, Score loss: 2099.825004, Opp loss: 2057.101789, Result loss: 0.189223\n",
      "2006 Tournament: Accuracy: 68.0%, Score loss: 1509.174013, Opp loss: 1501.534832, Result loss: 0.214649\n",
      "2007 Tournament: Accuracy: 75.8%, Score loss: 1005.423444, Opp loss: 986.593487, Result loss: 0.154412\n",
      "2008 Tournament: Accuracy: 73.4%, Score loss: 1756.344094, Opp loss: 1762.241708, Result loss: 0.188136\n",
      "2009 Tournament: Accuracy: 75.8%, Score loss: 688.899846, Opp loss: 659.559645, Result loss: 0.156846\n",
      "2010 Tournament: Accuracy: 70.9%, Score loss: 2928.680827, Opp loss: 2970.513809, Result loss: 0.201694\n",
      "2011 Tournament: Accuracy: 66.9%, Score loss: 2188.494403, Opp loss: 2022.552420, Result loss: 0.242598\n",
      "2012 Tournament: Accuracy: 74.6%, Score loss: 2527.186043, Opp loss: 2823.683482, Result loss: 0.161203\n",
      "2013 Tournament: Accuracy: 66.2%, Score loss: 1758.954532, Opp loss: 1716.387977, Result loss: 0.234266\n",
      "2014 Tournament: Accuracy: 66.5%, Score loss: 3989.232995, Opp loss: 4189.061437, Result loss: 0.206791\n",
      "2015 Tournament: Accuracy: 70.8%, Score loss: 2956.026489, Opp loss: 3006.882365, Result loss: 0.184704\n",
      "2016 Tournament: Accuracy: 66.5%, Score loss: 2917.802077, Opp loss: 3013.135796, Result loss: 0.223094\n",
      "2017 Tournament: Accuracy: 70.0%, Score loss: 2518.194629, Opp loss: 2232.517842, Result loss: 0.211082\n",
      "2018 Tournament: Accuracy: 73.5%, Score loss: 3083.017402, Opp loss: 2872.125979, Result loss: 0.205046\n",
      "2019 Tournament: Accuracy: 73.1%, Score loss: 1518.319250, Opp loss: 1506.275941, Result loss: 0.164294\n",
      "2021 Tournament: Accuracy: 62.0%, Score loss: 2226.893009, Opp loss: 2325.135023, Result loss: 0.251369\n",
      "2022 Tournament: Accuracy: 67.5%, Score loss: 1834.044504, Opp loss: 1843.311466, Result loss: 0.225034\n",
      "2023 Tournament: Accuracy: 66.8%, Score loss: 2037.048934, Opp loss: 2066.463069, Result loss: 0.220383\n",
      "2024 Tournament: Accuracy: 68.7%, Score loss: 1819.320343, Opp loss: 1858.917275, Result loss: 0.186566\n"
     ]
    }
   ],
   "source": [
    "for season in tourney.Season.unique():\n",
    "    loader = DataLoader(gen_dataset(tourney[tourney.Season == season]), batch_size=batch_size)\n",
    "    test(loader, model, loss_fn, label=f\"{season} Tournament\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afd4bc-a7fc-43bd-a1b6-1b37a85f8f79",
   "metadata": {},
   "source": [
    "## Generating the submission file\n",
    "### Phase 1\n",
    "\n",
    "Write the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d25dfe-9ead-4100-bb12-fbab95124ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w') as f:\n",
    "    f.write(\"ID,Pred\\n\")\n",
    "    for season in range(2021, 2025):\n",
    "        for league in ('M', 'W'):\n",
    "            teams_to_test = sorted(teams[(teams.Season==season) & (teams.League==league)].TeamID.values)\n",
    "            matchups = [(t1, t2) for t1 in teams_to_test for t2 in teams_to_test if t1 < t2]\n",
    "            matchups_tensor = torch.Tensor([(teamMapping[(t1, season)], teamMapping[(t2, season)])\n",
    "                                     for (t1, t2) in matchups]).int().to(device)\n",
    "            _, _, predictions = model(matchups_tensor)\n",
    "            for (t1, t2), pred in zip(matchups, predictions):\n",
    "                f.write(f\"{season}_{t1.item()}_{t2.item()},{pred.item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e032b5e-322d-49a5-a9a7-9d34972a56dd",
   "metadata": {},
   "source": [
    "Two teams canceled their 2021 season due to covid but are still in the sample submission. Add in their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f04744c-8b58-42a4-8834-00e38e08e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv', 'a') as f:\n",
    "    for missing_team in [3169, 3197]:\n",
    "        for opponent in teams[(teams.Season==2021) & (teams.League=='W')].TeamID.values:\n",
    "            if opponent > missing_team:\n",
    "                f.write(f\"2021_{missing_team}_{opponent},0\\n\")\n",
    "            else:\n",
    "                f.write(f\"2021_{opponent}_{missing_team},1\\n\")\n",
    "    f.write(f\"2021_3169_3197,0.5\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3b7d8-88d5-4f18-aad2-ce4ede2941f9",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c29f148-ac3b-47fa-9ed5-dd4f7fa6852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd9be8-bb71-428e-8511-32b1da1d6797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
