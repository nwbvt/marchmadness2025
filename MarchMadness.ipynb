{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b53588-2c8e-4166-b01d-037b765c2d69",
   "metadata": {},
   "source": [
    "# March Madness 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd96dd0b-1844-4dca-9495-b722deda29ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81669670-3bd9-4cc0-b0e8-d76f32dfd61f",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "Each team can be modeled by x hidden features. In each game, these hidden features interact in a nonlinear fashion to determine the outcome of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef008b05-6dc7-46e7-9783-2499977b8249",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5186f8-4158-462e-9d34-da6230804b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "      <td>116723.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2014.051044</td>\n",
       "      <td>70.072462</td>\n",
       "      <td>1288.243422</td>\n",
       "      <td>75.859651</td>\n",
       "      <td>1283.044987</td>\n",
       "      <td>63.857732</td>\n",
       "      <td>0.068658</td>\n",
       "      <td>26.392099</td>\n",
       "      <td>55.746305</td>\n",
       "      <td>7.339085</td>\n",
       "      <td>...</td>\n",
       "      <td>20.138276</td>\n",
       "      <td>12.072488</td>\n",
       "      <td>17.736907</td>\n",
       "      <td>10.480668</td>\n",
       "      <td>21.632934</td>\n",
       "      <td>11.405867</td>\n",
       "      <td>13.737130</td>\n",
       "      <td>5.901031</td>\n",
       "      <td>3.144239</td>\n",
       "      <td>19.324709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.464256</td>\n",
       "      <td>35.845605</td>\n",
       "      <td>105.298971</td>\n",
       "      <td>11.007412</td>\n",
       "      <td>104.764160</td>\n",
       "      <td>10.851210</td>\n",
       "      <td>0.305052</td>\n",
       "      <td>4.683480</td>\n",
       "      <td>7.461328</td>\n",
       "      <td>3.116574</td>\n",
       "      <td>...</td>\n",
       "      <td>6.064958</td>\n",
       "      <td>5.345290</td>\n",
       "      <td>7.085348</td>\n",
       "      <td>4.221941</td>\n",
       "      <td>4.519345</td>\n",
       "      <td>3.724047</td>\n",
       "      <td>4.536147</td>\n",
       "      <td>2.778302</td>\n",
       "      <td>2.628125</td>\n",
       "      <td>4.551727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1287.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1282.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1381.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Season         DayNum        WTeamID         WScore  \\\n",
       "count  116723.000000  116723.000000  116723.000000  116723.000000   \n",
       "mean     2014.051044      70.072462    1288.243422      75.859651   \n",
       "std         6.464256      35.845605     105.298971      11.007412   \n",
       "min      2003.000000       0.000000    1101.000000      34.000000   \n",
       "25%      2009.000000      38.000000    1199.000000      68.000000   \n",
       "50%      2014.000000      73.000000    1287.000000      75.000000   \n",
       "75%      2020.000000     101.000000    1381.000000      83.000000   \n",
       "max      2025.000000     132.000000    1480.000000     149.000000   \n",
       "\n",
       "             LTeamID         LScore          NumOT           WFGM  \\\n",
       "count  116723.000000  116723.000000  116723.000000  116723.000000   \n",
       "mean     1283.044987      63.857732       0.068658      26.392099   \n",
       "std       104.764160      10.851210       0.305052       4.683480   \n",
       "min      1101.000000      20.000000       0.000000      10.000000   \n",
       "25%      1192.000000      57.000000       0.000000      23.000000   \n",
       "50%      1282.000000      64.000000       0.000000      26.000000   \n",
       "75%      1374.000000      71.000000       0.000000      29.000000   \n",
       "max      1480.000000     144.000000       6.000000      57.000000   \n",
       "\n",
       "                WFGA          WFGM3  ...          LFGA3           LFTM  \\\n",
       "count  116723.000000  116723.000000  ...  116723.000000  116723.000000   \n",
       "mean       55.746305       7.339085  ...      20.138276      12.072488   \n",
       "std         7.461328       3.116574  ...       6.064958       5.345290   \n",
       "min        26.000000       0.000000  ...       1.000000       0.000000   \n",
       "25%        51.000000       5.000000  ...      16.000000       8.000000   \n",
       "50%        55.000000       7.000000  ...      20.000000      12.000000   \n",
       "75%        60.000000       9.000000  ...      24.000000      15.000000   \n",
       "max       103.000000      26.000000  ...      59.000000      48.000000   \n",
       "\n",
       "                LFTA            LOR            LDR           LAst  \\\n",
       "count  116723.000000  116723.000000  116723.000000  116723.000000   \n",
       "mean       17.736907      10.480668      21.632934      11.405867   \n",
       "std         7.085348       4.221941       4.519345       3.724047   \n",
       "min         0.000000       0.000000       4.000000       0.000000   \n",
       "25%        13.000000       7.000000      19.000000       9.000000   \n",
       "50%        17.000000      10.000000      21.000000      11.000000   \n",
       "75%        22.000000      13.000000      25.000000      14.000000   \n",
       "max        65.000000      36.000000      49.000000      31.000000   \n",
       "\n",
       "                 LTO           LStl           LBlk            LPF  \n",
       "count  116723.000000  116723.000000  116723.000000  116723.000000  \n",
       "mean       13.737130       5.901031       3.144239      19.324709  \n",
       "std         4.536147       2.778302       2.628125       4.551727  \n",
       "min         0.000000       0.000000       0.000000       4.000000  \n",
       "25%        11.000000       4.000000       1.000000      16.000000  \n",
       "50%        13.000000       6.000000       3.000000      19.000000  \n",
       "75%        17.000000       8.000000       4.000000      22.000000  \n",
       "max        41.000000      22.000000      33.000000      45.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mens = pd.read_csv('data/MRegularSeasonDetailedResults.csv')\n",
    "mens['League'] = 'M'\n",
    "mens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3be43b-6f29-44ab-bd21-55159ffe58be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "      <td>79639.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017.310476</td>\n",
       "      <td>68.860759</td>\n",
       "      <td>3285.050867</td>\n",
       "      <td>71.711963</td>\n",
       "      <td>3286.594658</td>\n",
       "      <td>57.234370</td>\n",
       "      <td>0.051583</td>\n",
       "      <td>25.847537</td>\n",
       "      <td>58.980010</td>\n",
       "      <td>6.268876</td>\n",
       "      <td>...</td>\n",
       "      <td>17.913974</td>\n",
       "      <td>10.511119</td>\n",
       "      <td>15.515175</td>\n",
       "      <td>11.395447</td>\n",
       "      <td>22.441116</td>\n",
       "      <td>10.933688</td>\n",
       "      <td>16.745024</td>\n",
       "      <td>6.923831</td>\n",
       "      <td>3.434950</td>\n",
       "      <td>18.204184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.531798</td>\n",
       "      <td>36.258086</td>\n",
       "      <td>104.022507</td>\n",
       "      <td>11.547894</td>\n",
       "      <td>105.457243</td>\n",
       "      <td>10.964583</td>\n",
       "      <td>0.258755</td>\n",
       "      <td>4.982451</td>\n",
       "      <td>7.975729</td>\n",
       "      <td>3.125925</td>\n",
       "      <td>...</td>\n",
       "      <td>6.469817</td>\n",
       "      <td>4.938106</td>\n",
       "      <td>6.632564</td>\n",
       "      <td>4.639725</td>\n",
       "      <td>4.939763</td>\n",
       "      <td>3.805204</td>\n",
       "      <td>5.597689</td>\n",
       "      <td>3.279905</td>\n",
       "      <td>3.666537</td>\n",
       "      <td>4.557235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3101.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3101.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3196.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3195.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>3283.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>3287.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>3376.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3377.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Season        DayNum       WTeamID        WScore       LTeamID  \\\n",
       "count  79639.000000  79639.000000  79639.000000  79639.000000  79639.000000   \n",
       "mean    2017.310476     68.860759   3285.050867     71.711963   3286.594658   \n",
       "std        4.531798     36.258086    104.022507     11.547894    105.457243   \n",
       "min     2010.000000      0.000000   3101.000000     30.000000   3101.000000   \n",
       "25%     2013.000000     35.000000   3196.000000     64.000000   3195.000000   \n",
       "50%     2017.000000     72.000000   3283.000000     71.000000   3287.000000   \n",
       "75%     2021.000000    101.000000   3376.000000     79.000000   3377.000000   \n",
       "max     2025.000000    132.000000   3480.000000    140.000000   3480.000000   \n",
       "\n",
       "             LScore         NumOT          WFGM          WFGA         WFGM3  \\\n",
       "count  79639.000000  79639.000000  79639.000000  79639.000000  79639.000000   \n",
       "mean      57.234370      0.051583     25.847537     58.980010      6.268876   \n",
       "std       10.964583      0.258755      4.982451      7.975729      3.125925   \n",
       "min       11.000000      0.000000      9.000000     30.000000      0.000000   \n",
       "25%       50.000000      0.000000     22.000000     53.000000      4.000000   \n",
       "50%       57.000000      0.000000     25.000000     59.000000      6.000000   \n",
       "75%       64.000000      0.000000     29.000000     64.000000      8.000000   \n",
       "max      130.000000      5.000000     58.000000    113.000000     30.000000   \n",
       "\n",
       "       ...         LFGA3          LFTM          LFTA           LOR  \\\n",
       "count  ...  79639.000000  79639.000000  79639.000000  79639.000000   \n",
       "mean   ...     17.913974     10.511119     15.515175     11.395447   \n",
       "std    ...      6.469817      4.938106      6.632564      4.639725   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...     13.000000      7.000000     11.000000      8.000000   \n",
       "50%    ...     17.000000     10.000000     15.000000     11.000000   \n",
       "75%    ...     22.000000     14.000000     20.000000     14.000000   \n",
       "max    ...     80.000000     37.000000     52.000000     38.000000   \n",
       "\n",
       "                LDR          LAst           LTO          LStl          LBlk  \\\n",
       "count  79639.000000  79639.000000  79639.000000  79639.000000  79639.000000   \n",
       "mean      22.441116     10.933688     16.745024      6.923831      3.434950   \n",
       "std        4.939763      3.805204      5.597689      3.279905      3.666537   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       19.000000      8.000000     13.000000      5.000000      1.000000   \n",
       "50%       22.000000     11.000000     16.000000      7.000000      3.000000   \n",
       "75%       26.000000     13.000000     20.000000      9.000000      4.000000   \n",
       "max       53.000000     34.000000     49.000000     26.000000     42.000000   \n",
       "\n",
       "                LPF  \n",
       "count  79639.000000  \n",
       "mean      18.204184  \n",
       "std        4.557235  \n",
       "min        3.000000  \n",
       "25%       15.000000  \n",
       "50%       18.000000  \n",
       "75%       21.000000  \n",
       "max       47.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womens = pd.read_csv('data/WRegularSeasonDetailedResults.csv')\n",
    "womens['League'] = 'W'\n",
    "womens.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a57ce-cca2-4b81-a8a2-ad8638faefbe",
   "metadata": {},
   "source": [
    "The IDs are definitely distinct so we can combine into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c18b78-f8fb-439f-bdeb-079abb4516f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = pd.concat([mens, womens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6210e5c-c7a9-4ec3-95f6-b4a963a6d191",
   "metadata": {},
   "source": [
    "Get the distinct team/Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2206f762-b26b-49a2-b97a-94929f7273e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat([all_teams[['WTeamID', 'Season', 'League']].rename(columns={'WTeamID': 'TeamID'}),\n",
    "                   all_teams[['LTeamID', 'Season', 'League']].rename(columns={'LTeamID': 'TeamID'})]).drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee119045-207e-4dae-9ec7-1ef186642f48",
   "metadata": {},
   "source": [
    "Define the training data. The x's will be the indexes of two team IDs, the y's will be 1 if the first team won, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607aaaf7-13f0-461e-8b2a-7477c1f57bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teamMapping = {(x.TeamID, x.Season): x.Index for x in teams.itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d52abd-7d74-4996-a93b-ab2e578bdf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>League</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79634</th>\n",
       "      <td>2025</td>\n",
       "      <td>84</td>\n",
       "      <td>3450</td>\n",
       "      <td>65</td>\n",
       "      <td>3333</td>\n",
       "      <td>57</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79635</th>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>3129</td>\n",
       "      <td>89</td>\n",
       "      <td>3307</td>\n",
       "      <td>80</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79636</th>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>3234</td>\n",
       "      <td>85</td>\n",
       "      <td>3321</td>\n",
       "      <td>80</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79637</th>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>3337</td>\n",
       "      <td>55</td>\n",
       "      <td>3258</td>\n",
       "      <td>43</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79638</th>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>3475</td>\n",
       "      <td>72</td>\n",
       "      <td>3287</td>\n",
       "      <td>52</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196362 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  \\\n",
       "0        2003      10     1104      68     1328      62    N      0    27   \n",
       "1        2003      10     1272      70     1393      63    N      0    26   \n",
       "2        2003      11     1266      73     1437      61    N      0    24   \n",
       "3        2003      11     1296      56     1457      50    N      0    18   \n",
       "4        2003      11     1400      77     1208      71    N      0    30   \n",
       "...       ...     ...      ...     ...      ...     ...  ...    ...   ...   \n",
       "79634    2025      84     3450      65     3333      57    A      0    24   \n",
       "79635    2025      85     3129      89     3307      80    H      0    33   \n",
       "79636    2025      85     3234      85     3321      80    H      0    29   \n",
       "79637    2025      85     3337      55     3258      43    H      0    21   \n",
       "79638    2025      85     3475      72     3287      52    A      0    26   \n",
       "\n",
       "       WFGA  ...  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  League  \n",
       "0        58  ...    16    22   10   22     8   18     9     2   20       M  \n",
       "1        62  ...     9    20   20   25     7   12     8     6   16       M  \n",
       "2        58  ...    14    23   31   22     9   12     2     5   23       M  \n",
       "3        38  ...     8    15   17   20     9   19     4     3   23       M  \n",
       "4        61  ...    17    27   21   15    12   10     7     1   14       M  \n",
       "...     ...  ...   ...   ...  ...  ...   ...  ...   ...   ...  ...     ...  \n",
       "79634    58  ...     7     9   11   23    10    8     5    10   14       W  \n",
       "79635    73  ...     7    16    4   25    16    4     2    13   13       W  \n",
       "79636    60  ...    13    20    6   25    18    8     2    13   21       W  \n",
       "79637    50  ...    14    17   11   20     6    8     2    10   13       W  \n",
       "79638    52  ...     8    10    9   14     8   10     6    21   16       W  \n",
       "\n",
       "[196362 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29542fc9-8986-46fe-a6b3-91213898f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = all_teams.apply(lambda x: teamMapping[(x.WTeamID, x.Season)], axis=1)\n",
    "losers = all_teams.apply(lambda x: teamMapping[(x.LTeamID, x.Season)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a6129-688e-4fef-bf69-17aa7cfad9a5",
   "metadata": {},
   "source": [
    "Try modeling the score differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49dffc37-5f7a-49eb-b59c-52733d0d9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diffs = all_teams.WScore - all_teams.LScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57ad178-fdaf-4e87-a0b7-959876a5d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.from_numpy(np.concatenate([np.stack([winners, losers], axis=1), np.stack([losers, winners], axis=1)]))\n",
    "y_tensor = torch.from_numpy(np.concatenate([score_diffs, -score_diffs])).reshape([-1,1]).double()\n",
    "dataset = TensorDataset(x_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e570534-09f4-4e6a-b9bd-e77e52014ce5",
   "metadata": {},
   "source": [
    "Generate the train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edbc8b7f-0b20-4f49-92e9-f16cadfeeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "generator = torch.Generator().manual_seed(20250217)\n",
    "train_data, validation_data = torch.utils.data.random_split(dataset, [0.9, 0.1], generator=generator)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50ea84-42ce-462c-a3b3-3928a04aa7ef",
   "metadata": {},
   "source": [
    "## The Model\n",
    "Define the model. Combine the embeddings for the two teams, go to a hidden layer, and then output to a prediction if the first team won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5dbb96c-d80f-454e-bdda-f2d9eadd3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_size=64, model_size=16, dropout=0.1):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(teams), embedding_size)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(2*embedding_size, model_size)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.score_fc = nn.Linear(model_size, 1)\n",
    "        self.result_fc = nn.Linear(model_size, 1)\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        team = self.embedding(x[:,0])\n",
    "        opponent = self.embedding(x[:,1])\n",
    "        matchup = self.dropout1(torch.cat([team, opponent], axis=1))\n",
    "        hidden = self.dropout2(F.relu(self.fc1(matchup)))\n",
    "        score = self.score_fc(hidden)\n",
    "        result = self.result_fc(hidden)\n",
    "        return score, result \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5629261-0b6d-44c9-828e-698e86006f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(embedding_size=128, model_size=32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98325a-8ba0-466f-b3ca-6991e8450a08",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cb92ad-908f-44a7-a2a0-88dd9d4d51ab",
   "metadata": {},
   "source": [
    "Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ab2ee77-d1dd-444f-b7bc-b5e7d057ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "def train(data, model, loss_fn, optimizer, log=False):\n",
    "    size = len(data.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(data):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred_score, pred_result = model(x)\n",
    "        score_loss = loss_fn(pred_score, y)\n",
    "        result_loss = loss_fn(pred_result, (y > 0).double())\n",
    "\n",
    "        (score_loss + result_loss).backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if log and batch % 1000 == 0:\n",
    "            score_loss, result_loss, current = score_loss.item(), result_loss.item(), (batch + 1) * len(x)\n",
    "            print(f\"score loss: {score_loss:>7f}, result loss: {result_loss:>7f} [{current:>6d}/{size:>6d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadb0b3-4e99-47a2-8fee-846467b01b86",
   "metadata": {},
   "source": [
    "Define the testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3466d44f-fc82-46a7-95e1-0590674e7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, model, loss_fn, label=\"Test\"):\n",
    "    size = len(data.dataset)\n",
    "    num_batches = len(data)\n",
    "    model.eval()\n",
    "    score_loss, result_loss, correct = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            score_pred, result_pred = model(x)\n",
    "            score_loss += loss_fn(score_pred, y).item()\n",
    "            result_loss += loss_fn(result_pred, (y > 0).float())\n",
    "            correct += ((result_pred >= 0.5) == (y > 0)).type(torch.float).sum().item()\n",
    "    score_loss /= num_batches\n",
    "    result_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"{label} Error: Accuracy: {(100*correct):>0.1f}%, Avg score loss: {score_loss:>8f}, Avg result loss: {result_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fca87-08c7-48e0-92dd-52ef4ff8463f",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fba01505-0d95-404d-802a-e4922ab226a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "score loss: 334.471988, result loss: 0.476096 [    32/353452]\n",
      "score loss: 302.613749, result loss: 0.391279 [ 32032/353452]\n",
      "score loss: 288.009242, result loss: 0.261286 [ 64032/353452]\n",
      "score loss: 240.909307, result loss: 0.300321 [ 96032/353452]\n",
      "score loss: 281.345915, result loss: 0.281104 [128032/353452]\n",
      "score loss: 224.945068, result loss: 0.266802 [160032/353452]\n",
      "score loss: 194.466044, result loss: 0.291128 [192032/353452]\n",
      "score loss: 318.072640, result loss: 0.266847 [224032/353452]\n",
      "score loss: 279.972306, result loss: 0.250939 [256032/353452]\n",
      "score loss: 287.624735, result loss: 0.246050 [288032/353452]\n",
      "score loss: 229.493105, result loss: 0.233772 [320032/353452]\n",
      "score loss: 233.766236, result loss: 0.256219 [352032/353452]\n",
      "Train Error: Accuracy: 53.7%, Avg score loss: 266.830870, Avg result loss: 0.251377\n",
      "Validation Error: Accuracy: 53.4%, Avg score loss: 265.878485, Avg result loss: 0.252369\n",
      "Epoch 1\n",
      "Train Error: Accuracy: 61.0%, Avg score loss: 242.551075, Avg result loss: 0.232032\n",
      "Validation Error: Accuracy: 59.8%, Avg score loss: 245.264799, Avg result loss: 0.235237\n",
      "Epoch 2\n",
      "Train Error: Accuracy: 66.3%, Avg score loss: 214.035168, Avg result loss: 0.213246\n",
      "Validation Error: Accuracy: 64.8%, Avg score loss: 220.628593, Avg result loss: 0.218638\n",
      "Epoch 3\n",
      "Train Error: Accuracy: 70.0%, Avg score loss: 186.749674, Avg result loss: 0.196359\n",
      "Validation Error: Accuracy: 68.2%, Avg score loss: 196.241288, Avg result loss: 0.203573\n",
      "Epoch 4\n",
      "Train Error: Accuracy: 72.5%, Avg score loss: 164.591863, Avg result loss: 0.183634\n",
      "Validation Error: Accuracy: 70.7%, Avg score loss: 175.592065, Avg result loss: 0.191655\n",
      "Epoch 5\n",
      "Train Error: Accuracy: 74.2%, Avg score loss: 148.592858, Avg result loss: 0.175041\n",
      "Validation Error: Accuracy: 72.5%, Avg score loss: 160.222736, Avg result loss: 0.183309\n",
      "Epoch 6\n",
      "Train Error: Accuracy: 75.3%, Avg score loss: 137.859413, Avg result loss: 0.169972\n",
      "Validation Error: Accuracy: 73.4%, Avg score loss: 149.658388, Avg result loss: 0.178129\n",
      "Epoch 7\n",
      "Train Error: Accuracy: 75.9%, Avg score loss: 130.966800, Avg result loss: 0.167077\n",
      "Validation Error: Accuracy: 73.9%, Avg score loss: 142.643930, Avg result loss: 0.175098\n",
      "Epoch 8\n",
      "Train Error: Accuracy: 76.3%, Avg score loss: 126.446011, Avg result loss: 0.165777\n",
      "Validation Error: Accuracy: 74.3%, Avg score loss: 138.099058, Avg result loss: 0.173511\n",
      "Epoch 9\n",
      "Train Error: Accuracy: 76.5%, Avg score loss: 123.444748, Avg result loss: 0.165196\n",
      "Validation Error: Accuracy: 74.4%, Avg score loss: 135.085698, Avg result loss: 0.172762\n",
      "Epoch 10\n",
      "Train Error: Accuracy: 76.6%, Avg score loss: 121.433099, Avg result loss: 0.165260\n",
      "Validation Error: Accuracy: 74.6%, Avg score loss: 132.993720, Avg result loss: 0.172534\n",
      "Epoch 11\n",
      "Train Error: Accuracy: 76.7%, Avg score loss: 119.927998, Avg result loss: 0.165085\n",
      "Validation Error: Accuracy: 74.6%, Avg score loss: 131.344311, Avg result loss: 0.172255\n",
      "Epoch 12\n",
      "Train Error: Accuracy: 76.7%, Avg score loss: 118.991017, Avg result loss: 0.165373\n",
      "Validation Error: Accuracy: 74.8%, Avg score loss: 130.229016, Avg result loss: 0.172335\n",
      "Epoch 13\n",
      "Train Error: Accuracy: 76.8%, Avg score loss: 118.166240, Avg result loss: 0.165843\n",
      "Validation Error: Accuracy: 74.8%, Avg score loss: 129.371465, Avg result loss: 0.172585\n",
      "Epoch 14\n",
      "Train Error: Accuracy: 76.8%, Avg score loss: 117.540019, Avg result loss: 0.165990\n",
      "Validation Error: Accuracy: 74.9%, Avg score loss: 128.826175, Avg result loss: 0.172769\n",
      "Epoch 15\n",
      "Train Error: Accuracy: 76.8%, Avg score loss: 117.145870, Avg result loss: 0.166181\n",
      "Validation Error: Accuracy: 74.9%, Avg score loss: 128.357698, Avg result loss: 0.172892\n",
      "Epoch 16\n",
      "Train Error: Accuracy: 76.8%, Avg score loss: 116.802228, Avg result loss: 0.166525\n",
      "Validation Error: Accuracy: 74.9%, Avg score loss: 128.008139, Avg result loss: 0.173121\n",
      "Epoch 17\n",
      "Train Error: Accuracy: 76.8%, Avg score loss: 116.442203, Avg result loss: 0.166662\n",
      "Validation Error: Accuracy: 74.9%, Avg score loss: 127.695587, Avg result loss: 0.173255\n",
      "Epoch 18\n",
      "Train Error: Accuracy: 76.8%, Avg score loss: 116.114826, Avg result loss: 0.166808\n",
      "Validation Error: Accuracy: 75.1%, Avg score loss: 127.480841, Avg result loss: 0.173411\n",
      "Epoch 19\n",
      "Train Error: Accuracy: 76.8%, Avg score loss: 115.958501, Avg result loss: 0.167003\n",
      "Validation Error: Accuracy: 75.1%, Avg score loss: 127.330098, Avg result loss: 0.173577\n",
      "Epoch 20\n",
      "Train Error: Accuracy: 76.8%, Avg score loss: 115.764207, Avg result loss: 0.166963\n",
      "Validation Error: Accuracy: 75.1%, Avg score loss: 127.255073, Avg result loss: 0.173638\n",
      "Epoch 21\n",
      "Train Error: Accuracy: 76.9%, Avg score loss: 115.573839, Avg result loss: 0.166861\n",
      "Validation Error: Accuracy: 75.1%, Avg score loss: 127.173411, Avg result loss: 0.173668\n",
      "Epoch 22\n",
      "Train Error: Accuracy: 76.9%, Avg score loss: 115.424594, Avg result loss: 0.166924\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 127.149321, Avg result loss: 0.173769\n",
      "Epoch 23\n",
      "Train Error: Accuracy: 76.9%, Avg score loss: 115.199041, Avg result loss: 0.166945\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.992222, Avg result loss: 0.173766\n",
      "Epoch 24\n",
      "Train Error: Accuracy: 76.9%, Avg score loss: 115.018563, Avg result loss: 0.166902\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.957858, Avg result loss: 0.173862\n",
      "Epoch 25\n",
      "Train Error: Accuracy: 76.9%, Avg score loss: 114.880538, Avg result loss: 0.166861\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.898912, Avg result loss: 0.173871\n",
      "Epoch 26\n",
      "Train Error: Accuracy: 76.9%, Avg score loss: 114.737389, Avg result loss: 0.166743\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.880350, Avg result loss: 0.173871\n",
      "Epoch 27\n",
      "Train Error: Accuracy: 77.0%, Avg score loss: 114.615243, Avg result loss: 0.166904\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.892169, Avg result loss: 0.174001\n",
      "Epoch 28\n",
      "Train Error: Accuracy: 77.0%, Avg score loss: 114.456736, Avg result loss: 0.166694\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.844847, Avg result loss: 0.173942\n",
      "Epoch 29\n",
      "Train Error: Accuracy: 77.0%, Avg score loss: 114.345674, Avg result loss: 0.166780\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.750179, Avg result loss: 0.173965\n",
      "Epoch 30\n",
      "Train Error: Accuracy: 77.0%, Avg score loss: 114.180684, Avg result loss: 0.166581\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.748252, Avg result loss: 0.173889\n",
      "Epoch 31\n",
      "Train Error: Accuracy: 77.0%, Avg score loss: 114.046904, Avg result loss: 0.166674\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.741679, Avg result loss: 0.173980\n",
      "Epoch 32\n",
      "Train Error: Accuracy: 77.0%, Avg score loss: 113.933202, Avg result loss: 0.166504\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.668880, Avg result loss: 0.173963\n",
      "Epoch 33\n",
      "Train Error: Accuracy: 77.1%, Avg score loss: 113.770552, Avg result loss: 0.166428\n",
      "Validation Error: Accuracy: 74.9%, Avg score loss: 126.613877, Avg result loss: 0.173930\n",
      "Epoch 34\n",
      "Train Error: Accuracy: 77.1%, Avg score loss: 113.663053, Avg result loss: 0.166347\n",
      "Validation Error: Accuracy: 74.9%, Avg score loss: 126.610316, Avg result loss: 0.173976\n",
      "Epoch 35\n",
      "Train Error: Accuracy: 77.1%, Avg score loss: 113.522129, Avg result loss: 0.166220\n",
      "Validation Error: Accuracy: 74.9%, Avg score loss: 126.601906, Avg result loss: 0.173951\n",
      "Epoch 36\n",
      "Train Error: Accuracy: 77.2%, Avg score loss: 113.383932, Avg result loss: 0.166259\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.512767, Avg result loss: 0.174021\n",
      "Epoch 37\n",
      "Train Error: Accuracy: 77.2%, Avg score loss: 113.220446, Avg result loss: 0.166119\n",
      "Validation Error: Accuracy: 74.9%, Avg score loss: 126.548758, Avg result loss: 0.174041\n",
      "Epoch 38\n",
      "Train Error: Accuracy: 77.2%, Avg score loss: 113.061165, Avg result loss: 0.166285\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.532964, Avg result loss: 0.174171\n",
      "Epoch 39\n",
      "Train Error: Accuracy: 77.2%, Avg score loss: 112.923413, Avg result loss: 0.166024\n",
      "Validation Error: Accuracy: 75.0%, Avg score loss: 126.532832, Avg result loss: 0.174077\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Epoch {i}\")\n",
    "    train(train_loader, model, loss_fn, optimizer, log=(i==0))\n",
    "    test(train_loader, model, loss_fn, label=\"Train\")\n",
    "    test(validation_loader, model, loss_fn, label=\"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55a843-9fa3-443f-8342-410abd74688c",
   "metadata": {},
   "source": [
    "With this model we can predict the output of about three quarters of regular season games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe60ad-2cd9-4339-9600-62264350e6bd",
   "metadata": {},
   "source": [
    "## Load the tourney data to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093fcd61-386e-4330-b5af-e9d93df1b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "mens_tourney = pd.read_csv('data/MNCAATourneyDetailedResults.csv')\n",
    "womens_tourney = pd.read_csv('data/WNCAATourneyDetailedResults.csv')\n",
    "tourney = pd.concat([mens_tourney, womens_tourney])\n",
    "tourney_winners = tourney.apply(lambda x: teamMapping[(x.WTeamID, x.Season)], axis=1)\n",
    "tourney_losers = tourney.apply(lambda x: teamMapping[(x.LTeamID, x.Season)], axis=1)\n",
    "x_tourney_tensor = torch.from_numpy(np.concatenate([np.stack([tourney_winners, tourney_losers], axis=1), \n",
    "                                                    np.stack([tourney_losers, tourney_winners], axis=1)]))\n",
    "y_tourney_tensor = torch.from_numpy(np.concatenate([np.ones(len(tourney)), np.zeros(len(tourney))])).reshape([-1,1])\n",
    "tourney_dataset = TensorDataset(x_tourney_tensor, y_tourney_tensor)\n",
    "tourney_loader = DataLoader(tourney_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08340cd1-6cb0-400a-80fa-dda1171789bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tourney Error: Accuracy: 74.2%, Avg score loss: 170.450061, Avg result loss: 0.178833\n"
     ]
    }
   ],
   "source": [
    "test(tourney_loader, model, loss_fn, label=\"Tourney\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7c18a-8267-4926-a191-5c3a218bfde2",
   "metadata": {},
   "source": [
    "When it comes to tournament results we get about 7 out of 10 results. The lower result is likely due to teams having increased pairity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afd4bc-a7fc-43bd-a1b6-1b37a85f8f79",
   "metadata": {},
   "source": [
    "## Generating the submission file\n",
    "### Phase 1\n",
    "\n",
    "Write the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d25dfe-9ead-4100-bb12-fbab95124ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w') as f:\n",
    "    f.write(\"ID,Pred\\n\")\n",
    "    for season in range(2021, 2025):\n",
    "        for league in ('M', 'W'):\n",
    "            teams_to_test = sorted(teams[(teams.Season==season) & (teams.League==league)].TeamID.values)\n",
    "            matchups = [(t1, t2) for t1 in teams_to_test for t2 in teams_to_test if t1 < t2]\n",
    "            matchups_tensor = torch.Tensor([(teamMapping[(t1, season)], teamMapping[(t2, season)])\n",
    "                                     for (t1, t2) in matchups]).int().to(device)\n",
    "            _, predictions = model(matchups_tensor)\n",
    "            for (t1, t2), pred in zip(matchups, predictions):\n",
    "                f.write(f\"{season}_{t1.item()}_{t2.item()},{pred.item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e032b5e-322d-49a5-a9a7-9d34972a56dd",
   "metadata": {},
   "source": [
    "Two teams canceled their 2021 season due to covid but are still in the sample submission. Add in their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f04744c-8b58-42a4-8834-00e38e08e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv', 'a') as f:\n",
    "    for missing_team in [3169, 3197]:\n",
    "        for opponent in teams[(teams.Season==2021) & (teams.League=='W')].TeamID.values:\n",
    "            if opponent > missing_team:\n",
    "                f.write(f\"2021_{missing_team}_{opponent},0\\n\")\n",
    "            else:\n",
    "                f.write(f\"2021_{opponent}_{missing_team},1\\n\")\n",
    "    f.write(f\"2021_3169_3197,0.5\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
